{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2418aa36-305a-4890-8db5-efa2ddbfa398",
   "metadata": {},
   "source": [
    "<h1>test on 368 datapoints without any noise </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9245b7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 17:29:26.047048: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-16 17:29:26.047081: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import rdkit\n",
    "import deepchem as dc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import time\n",
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "#K-fold\n",
    "k_fold = 4\n",
    "k = k_fold\n",
    "max_epoch = 100\n",
    "# optimizer = tf.keras.optimizers.Adagrad(0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7cb7db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021.09.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdkit.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55e66389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dcd3310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.21.4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23b2d7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c79403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading molecular data\n",
    "df = pd.read_csv('molecule_parameters.csv')\n",
    "df.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1de144d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.697637870606162"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DDG Standard deviation\n",
    "np.std(df.ddg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b293820-dbc0-46dc-a50f-476c71ab9a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-34.07407324'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['entropy'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c51206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing entropy and add some noise\n",
    "# df['entropy'] = df['entropy'].astype(float) + np.random.normal(np.sqrt(df['entropy'].astype(float).mean()), 1, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "464c758b-2918-4ee7-8154-107187787a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['entropy'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1112109",
   "metadata": {},
   "source": [
    "# Reading PDB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66dad05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start time\n",
    "# start = time.time()\n",
    "# # Dictionary with complex names as keys and molecule as values\n",
    "# PDBs = {}\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "# # mypath = '../../../../../../Documents/GitHub/Binding-Free-Energy-Prediction-Host-Guest-System/pdbbind/raw-data/'\n",
    "# mypath = 'dataset234/'\n",
    "# onlyfiles = [f for f in listdir(mypath) if f not in ('.DS_Store') and f in (df['complex-name'].tolist())]\n",
    "# for f in onlyfiles:\n",
    "#     print(f)\n",
    "#     PDBs.update({f: rdkit.Chem.rdmolfiles.MolFromPDBFile(mypath + f + '/com_new.pqr')})\n",
    "\n",
    "# for key, value in dict(PDBs).items():\n",
    "#     if value is None:\n",
    "#         del PDBs[key]\n",
    "# time.sleep(1)\n",
    "# # end time\n",
    "# end = time.time()\n",
    "# # total time taken\n",
    "# print(f\"PDB file reading runtime is {(end - start)/60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50c4732a-e78e-4dfe-9aa5-f9fe582b5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Save PDB\n",
    "# import pickle\n",
    "# with open('PDBs-234.pkl', 'wb') as file:\n",
    "#     pickle.dump(PDBs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fedd496a-bcd2-4d0f-a36b-927c450274d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load PDB\n",
    "import pickle\n",
    "PDBs= {}\n",
    "with open('PDBs-368.pkl', 'rb') as file:\n",
    "    PDBs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f51da58f-d0db-4253-8218-af598244ccad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PDBs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c287b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffling the PDBs\n",
    "import random\n",
    "l = list(PDBs.items())\n",
    "random.shuffle(l)\n",
    "PDBs = dict(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a0bb9657-f14a-4ed1-9e7c-30b25fecb5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDB_names = list(PDBs.keys())\n",
    "df_500= pd.DataFrame()\n",
    "ddg_list= []\n",
    "for i in PDB_names:\n",
    "    ddg_list.append(float(df[df['complex-name']==i]['ddg']))\n",
    "df_500 = pd.DataFrame({'ddg': ddg_list}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3debd36a-1290-45c4-9adc-8165eb50004e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DDG distribution for dataset of ~500 datapoints\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.xlabel('ddg')\n",
    "df_500.plot.hist('ddg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bec9a04d-7ef6-4bcb-855b-8f88003a3210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PDBs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4773b4b",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2808df",
   "metadata": {},
   "source": [
    "<h3>PGNNS model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b458c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "# batch_size = int(len(pdb_names_train)/4)\n",
    "# batch_size\n",
    "# batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e277cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "\n",
    "class PGNNS(tf.keras.Model):\n",
    "\n",
    "  def modify_graphgather(self, batch_size):\n",
    "    self.readout.batch_size = batch_size\n",
    "    self.batch_size = batch_size\n",
    "  def __init__(self, batch_size):\n",
    "    super(PGNNS, self).__init__()\n",
    "    self.input_shapes = None\n",
    "    self.batch_size = batch_size\n",
    "    self.gc1 = GraphConv(128, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm1 = layers.BatchNormalization()\n",
    "    self.gp1 = GraphPool()\n",
    "\n",
    "    self.gc2 = GraphConv(128, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm2 = layers.BatchNormalization()\n",
    "    self.gp2 = GraphPool()\n",
    "\n",
    "    self.dense1 = layers.Dense(128, activation=tf.nn.tanh)\n",
    "    self.batch_norm3 = layers.BatchNormalization()\n",
    "    self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "    self.dense2 = layers.Dense(1)\n",
    "    self.dense3 = layers.Dense(1, \n",
    "         kernel_initializer=initializers.Constant([0.5, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1]),\n",
    "         bias_initializer=initializers.Zeros())\n",
    "\n",
    "  def call(self, inputs):\n",
    "    inputs = inputs[0]\n",
    "    x = []\n",
    "#     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "#                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "    for i in range(len(self.input_shapes)):\n",
    "        x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "    for i in range(1, len(self.input_shapes)):\n",
    "        x[i] = tf.cast(x[i], tf.int32)\n",
    "    x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 16])\n",
    "    gc1_output = self.gc1(x)\n",
    "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "    gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "    gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "    gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "    dense1_output = self.dense1(gp2_output)\n",
    "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "    readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "    \n",
    "    model_var = self.dense2(readout_output)\n",
    "    binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "    return self.dense3(binding_affinity)\n",
    "# PGNNS = PGNNS(train_split_index)\n",
    "# PGNNS.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32c45a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a06ba8",
   "metadata": {},
   "source": [
    "# K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bdbf0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-16 17:30:16.406745: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-16 17:30:16.406779: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-16 17:30:16.406805: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (exp-3-51): /proc/driver/nvidia/version does not exist\n",
      "2022-04-16 17:30:16.407901: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGNNS Model Fold # 0\n",
      "1/1 [==============================] - 8s 8s/step - loss: 15.4961\n",
      "1/1 [==============================] - 1s 1s/step - loss: 29346.5781\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20778.9160\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 1899.1882\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1320.8807\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 6321.0659\n",
      "1/1 [==============================] - 4s 4s/step - loss: 4550.3413\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 16844.2344\n",
      "1/1 [==============================] - 4s 4s/step - loss: 12042.3896\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 12659.2324\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9058.3291\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 3613.0315\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2592.2593\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 39.3254\n",
      "1/1 [==============================] - 3s 3s/step - loss: 27.7606\n",
      "1/1 [==============================] - 1s 756ms/step - loss: 3602.9036\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2552.0742\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 8010.0605\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5677.7583\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 7833.5884\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5550.7246\n",
      "1/1 [==============================] - 1s 707ms/step - loss: 4003.2449\n",
      "1/1 [==============================] - 5s 5s/step - loss: 2828.5579\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 591.8734\n",
      "1/1 [==============================] - 3s 3s/step - loss: 409.2601\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 335.9556\n",
      "1/1 [==============================] - 3s 3s/step - loss: 249.6096\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 2570.2241\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1855.4037\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 4378.3862\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3145.9688\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 3885.1960\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2791.0393\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 1814.9153\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1308.5947\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 198.2472\n",
      "1/1 [==============================] - 3s 3s/step - loss: 146.7789\n",
      "1/1 [==============================] - 1s 743ms/step - loss: 294.3550\n",
      "1/1 [==============================] - 4s 4s/step - loss: 205.0040\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 1573.5156\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1106.0118\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 2477.0554\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1741.7751\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 2088.8438\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1465.6335\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 899.5492\n",
      "1/1 [==============================] - 4s 4s/step - loss: 625.7993\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 73.9427\n",
      "1/1 [==============================] - 3s 3s/step - loss: 49.2453\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 239.9860\n",
      "1/1 [==============================] - 3s 3s/step - loss: 180.1230\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 970.6074\n",
      "1/1 [==============================] - 4s 4s/step - loss: 709.2878\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 1360.2152\n",
      "1/1 [==============================] - 4s 4s/step - loss: 989.4496\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 1006.8680\n",
      "1/1 [==============================] - 3s 3s/step - loss: 735.0556\n",
      "1/1 [==============================] - 1s 808ms/step - loss: 332.2595\n",
      "1/1 [==============================] - 3s 3s/step - loss: 247.1588\n",
      "1/1 [==============================] - 1s 746ms/step - loss: 19.4675\n",
      "1/1 [==============================] - 4s 4s/step - loss: 14.5682\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 283.2122\n",
      "1/1 [==============================] - 4s 4s/step - loss: 192.0416\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 715.3674\n",
      "1/1 [==============================] - 3s 3s/step - loss: 492.0146\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 799.6929\n",
      "1/1 [==============================] - 3s 3s/step - loss: 549.3849\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 466.2149\n",
      "1/1 [==============================] - 4s 4s/step - loss: 316.6891\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 96.4015\n",
      "1/1 [==============================] - 4s 4s/step - loss: 62.3359\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 44.8002\n",
      "1/1 [==============================] - 3s 3s/step - loss: 36.5467\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 270.6261\n",
      "1/1 [==============================] - 3s 3s/step - loss: 206.2418\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 442.4003\n",
      "1/1 [==============================] - 4s 4s/step - loss: 332.6893\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 350.6446\n",
      "1/1 [==============================] - 3s 3s/step - loss: 265.6133\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 120.2375\n",
      "1/1 [==============================] - 3s 3s/step - loss: 95.1647\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 20.2662\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.1912\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 132.2646\n",
      "1/1 [==============================] - 3s 3s/step - loss: 84.6481\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 284.2385\n",
      "1/1 [==============================] - 3s 3s/step - loss: 186.6332\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 284.0701\n",
      "1/1 [==============================] - 3s 3s/step - loss: 185.3435\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 141.9733\n",
      "1/1 [==============================] - 3s 3s/step - loss: 89.0461\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 27.8368\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.8977\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 47.1755\n",
      "1/1 [==============================] - 3s 3s/step - loss: 40.6307\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 130.9535\n",
      "1/1 [==============================] - 3s 3s/step - loss: 106.9423\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 149.7446\n",
      "1/1 [==============================] - 3s 3s/step - loss: 121.2818\n",
      "1/1 [==============================] - 1s 772ms/step - loss: 81.3663\n",
      "1/1 [==============================] - 3s 3s/step - loss: 68.0531\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 21.9561\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.9085\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 44.9734\n",
      "1/1 [==============================] - 3s 3s/step - loss: 26.2710\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 110.1542\n",
      "1/1 [==============================] - 3s 3s/step - loss: 67.2547\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 128.3946\n",
      "1/1 [==============================] - 3s 3s/step - loss: 78.9442\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 79.2920\n",
      "1/1 [==============================] - 3s 3s/step - loss: 47.2599\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 27.1323\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.2068\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 26.0063\n",
      "1/1 [==============================] - 3s 3s/step - loss: 21.8361\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 55.5632\n",
      "1/1 [==============================] - 3s 3s/step - loss: 47.0560\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 62.4237\n",
      "1/1 [==============================] - 3s 3s/step - loss: 52.5560\n",
      "1/1 [==============================] - 1s 659ms/step - loss: 37.3861\n",
      "1/1 [==============================] - 3s 3s/step - loss: 31.7206\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 19.6385\n",
      "1/1 [==============================] - 4s 4s/step - loss: 14.2464\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 34.9869\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.4383\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 60.4706\n",
      "1/1 [==============================] - 3s 3s/step - loss: 35.7107\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 60.7006\n",
      "1/1 [==============================] - 3s 3s/step - loss: 35.8800\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 37.2237\n",
      "1/1 [==============================] - 3s 3s/step - loss: 21.6664\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 20.2356\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.4579\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 24.4776\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.0382\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 33.5989\n",
      "1/1 [==============================] - 3s 3s/step - loss: 28.2803\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 30.0222\n",
      "1/1 [==============================] - 4s 4s/step - loss: 25.2005\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 20.7236\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.0234\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 22.2996\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.8119\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 34.1655\n",
      "1/1 [==============================] - 4s 4s/step - loss: 19.5228\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 39.9777\n",
      "1/1 [==============================] - 3s 3s/step - loss: 22.7620\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 32.4989\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.5165\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 22.1208\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.5965\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 19.8711\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.6611\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 22.9752\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.4973\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 22.9179\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.4136\n",
      "1/1 [==============================] - 1s 758ms/step - loss: 19.9579\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.7562\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 20.9756\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.1921\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 26.6076\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.2800\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 29.8612\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.8553\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 26.7612\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.2926\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 21.5714\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.2252\n",
      "1/1 [==============================] - 1s 713ms/step - loss: 19.6559\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.6453\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 20.3661\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.1883\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 20.2522\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.0301\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 19.6806\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.5119\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 21.2069\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.0627\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 24.2402\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.0161\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 25.3495\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.4397\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 23.3463\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.6086\n",
      "1/1 [==============================] - 1s 761ms/step - loss: 20.7267\n",
      "1/1 [==============================] - 3s 3s/step - loss: 12.9368\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 19.7380\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.3362\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 19.7471\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.8570\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 19.7269\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.5297\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 20.2229\n",
      "1/1 [==============================] - 3s 3s/step - loss: 12.9419\n",
      "1/1 [==============================] - 1s 737ms/step - loss: 21.7596\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13.0201\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 23.2029\n",
      "1/1 [==============================] - 4s 4s/step - loss: 13.4257\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 22.9880\n",
      "1/1 [==============================] - 1s 948ms/step - loss: 22.9880\n",
      "[4.794584143528509]\n",
      "PGNNS Model Fold # 1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 17.2618\n",
      "1/1 [==============================] - 1s 1s/step - loss: 14650.7812\n",
      "1/1 [==============================] - 3s 3s/step - loss: 24578.9688\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 14.3252\n",
      "1/1 [==============================] - 4s 4s/step - loss: 17.0785\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 12164.6904\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20339.9199\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 10120.8564\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16877.2207\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 809.5951\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1322.1926\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 2987.3523\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5047.9453\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 8517.9297\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14422.9404\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 5007.3159\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8534.7617\n",
      "1/1 [==============================] - 1s 586ms/step - loss: 201.9810\n",
      "1/1 [==============================] - 3s 3s/step - loss: 353.4899\n",
      "1/1 [==============================] - 1s 573ms/step - loss: 2085.1472\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3417.9570\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 5472.2729\n",
      "1/1 [==============================] - 3s 3s/step - loss: 9064.2432\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 3679.6387\n",
      "1/1 [==============================] - 4s 4s/step - loss: 6082.9561\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 360.6591\n",
      "1/1 [==============================] - 4s 4s/step - loss: 574.7101\n",
      "1/1 [==============================] - 1s 559ms/step - loss: 825.4077\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1401.0677\n",
      "1/1 [==============================] - 1s 583ms/step - loss: 3182.9812\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5366.5703\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 2823.5667\n",
      "1/1 [==============================] - 4s 4s/step - loss: 4743.0757\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 599.3928\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1006.9705\n",
      "1/1 [==============================] - 1s 574ms/step - loss: 198.2728\n",
      "1/1 [==============================] - 4s 4s/step - loss: 317.5813\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 1705.1422\n",
      "1/1 [==============================] - 4s 4s/step - loss: 2824.7073\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 2122.3184\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3516.6797\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 813.2089\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1332.6757\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 14.9308\n",
      "1/1 [==============================] - 4s 4s/step - loss: 18.3550\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 746.3695\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1253.7732\n",
      "1/1 [==============================] - 1s 584ms/step - loss: 1404.6938\n",
      "1/1 [==============================] - 4s 4s/step - loss: 2355.6750\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 826.2313\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1385.6436\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 61.6039\n",
      "1/1 [==============================] - 4s 4s/step - loss: 98.2598\n",
      "1/1 [==============================] - 1s 735ms/step - loss: 268.6962\n",
      "1/1 [==============================] - 4s 4s/step - loss: 435.1017\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 854.3407\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1406.0737\n",
      "1/1 [==============================] - 1s 566ms/step - loss: 734.3674\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1203.5942\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 159.9280\n",
      "1/1 [==============================] - 4s 4s/step - loss: 250.6750\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 61.7270\n",
      "1/1 [==============================] - 4s 4s/step - loss: 102.4342\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 439.7726\n",
      "1/1 [==============================] - 4s 4s/step - loss: 749.2729\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 536.3347\n",
      "1/1 [==============================] - 4s 4s/step - loss: 912.2747\n",
      "1/1 [==============================] - 1s 594ms/step - loss: 199.0232\n",
      "1/1 [==============================] - 3s 3s/step - loss: 338.8395\n",
      "1/1 [==============================] - 1s 572ms/step - loss: 15.7849\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.8081\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 225.8312\n",
      "1/1 [==============================] - 3s 3s/step - loss: 356.0844\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 388.7580\n",
      "1/1 [==============================] - 4s 4s/step - loss: 623.1058\n",
      "1/1 [==============================] - 1s 576ms/step - loss: 217.8327\n",
      "1/1 [==============================] - 3s 3s/step - loss: 344.6103\n",
      "1/1 [==============================] - 1s 558ms/step - loss: 21.4617\n",
      "1/1 [==============================] - 3s 3s/step - loss: 26.3981\n",
      "1/1 [==============================] - 1s 588ms/step - loss: 91.4587\n",
      "1/1 [==============================] - 4s 4s/step - loss: 151.9499\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 233.5960\n",
      "1/1 [==============================] - 3s 3s/step - loss: 394.1929\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 176.8598\n",
      "1/1 [==============================] - 3s 3s/step - loss: 297.1148\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 33.7632\n",
      "1/1 [==============================] - 4s 4s/step - loss: 51.6130\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 42.0883\n",
      "1/1 [==============================] - 4s 4s/step - loss: 60.5217\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 147.8991\n",
      "1/1 [==============================] - 4s 4s/step - loss: 235.9330\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 145.0298\n",
      "1/1 [==============================] - 4s 4s/step - loss: 231.7431\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 45.1830\n",
      "1/1 [==============================] - 4s 4s/step - loss: 66.4838\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 19.8005\n",
      "1/1 [==============================] - 5s 5s/step - loss: 26.0713\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 85.3315\n",
      "1/1 [==============================] - 5s 5s/step - loss: 137.1869\n",
      "1/1 [==============================] - 1s 803ms/step - loss: 104.2151\n",
      "1/1 [==============================] - 5s 5s/step - loss: 169.4883\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 44.3532\n",
      "1/1 [==============================] - 5s 5s/step - loss: 68.6355\n",
      "1/1 [==============================] - 1s 590ms/step - loss: 14.4667\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.3523\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 53.5808\n",
      "1/1 [==============================] - 6s 6s/step - loss: 80.2400\n",
      "1/1 [==============================] - 1s 587ms/step - loss: 77.1932\n",
      "1/1 [==============================] - 4s 4s/step - loss: 119.5842\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 42.5908\n",
      "1/1 [==============================] - 5s 5s/step - loss: 62.2772\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 13.9135\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.2691\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 33.5849\n",
      "1/1 [==============================] - 7s 7s/step - loss: 49.0807\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 53.9573\n",
      "1/1 [==============================] - 5s 5s/step - loss: 83.4542\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 35.8725\n",
      "1/1 [==============================] - 5s 5s/step - loss: 52.7761\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 14.3162\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.0831\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 24.5570\n",
      "1/1 [==============================] - 7s 7s/step - loss: 32.8111\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 40.4078\n",
      "1/1 [==============================] - 5s 5s/step - loss: 59.2098\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 30.8222\n",
      "1/1 [==============================] - 5s 5s/step - loss: 43.2652\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 14.8098\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.6687\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 19.2446\n",
      "1/1 [==============================] - 7s 7s/step - loss: 24.3923\n",
      "1/1 [==============================] - 1s 747ms/step - loss: 30.4574\n",
      "1/1 [==============================] - 7s 7s/step - loss: 43.2025\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 25.6831\n",
      "1/1 [==============================] - 5s 5s/step - loss: 35.1068\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 14.7979\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.7372\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 16.9114\n",
      "1/1 [==============================] - 7s 7s/step - loss: 20.0519\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 24.7769\n",
      "1/1 [==============================] - 6s 6s/step - loss: 33.0725\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 22.2771\n",
      "1/1 [==============================] - 5s 5s/step - loss: 28.9096\n",
      "1/1 [==============================] - 1s 592ms/step - loss: 14.7450\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.4277\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 15.5275\n",
      "1/1 [==============================] - 5s 5s/step - loss: 17.8762\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 20.7118\n",
      "1/1 [==============================] - 5s 5s/step - loss: 26.6461\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 19.2846\n",
      "1/1 [==============================] - 5s 5s/step - loss: 24.2712\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 14.3731\n",
      "1/1 [==============================] - 6s 6s/step - loss: 15.9311\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 14.9132\n",
      "1/1 [==============================] - 6s 6s/step - loss: 16.6878\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 18.4538\n",
      "1/1 [==============================] - 7s 7s/step - loss: 22.5111\n",
      "1/1 [==============================] - 1s 744ms/step - loss: 17.5859\n",
      "1/1 [==============================] - 7s 7s/step - loss: 21.0290\n",
      "1/1 [==============================] - 1s 775ms/step - loss: 14.2255\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.4969\n",
      "1/1 [==============================] - 1s 752ms/step - loss: 14.5045\n",
      "1/1 [==============================] - 7s 7s/step - loss: 16.0295\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 16.8154\n",
      "1/1 [==============================] - 7s 7s/step - loss: 19.8608\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 16.2768\n",
      "1/1 [==============================] - 6s 6s/step - loss: 18.7932\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 14.0850\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.1354\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 14.2664\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.6188\n",
      "1/1 [==============================] - 1s 735ms/step - loss: 15.7194\n",
      "1/1 [==============================] - 6s 6s/step - loss: 18.1210\n",
      "1/1 [==============================] - 1s 855ms/step - loss: 15.2448\n",
      "1/1 [==============================] - 6s 6s/step - loss: 17.2287\n",
      "1/1 [==============================] - 1s 848ms/step - loss: 13.8815\n",
      "1/1 [==============================] - 5s 5s/step - loss: 14.8597\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 14.2594\n",
      "1/1 [==============================] - 7s 7s/step - loss: 15.3472\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 15.2508\n",
      "1/1 [==============================] - 6s 6s/step - loss: 16.9521\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 14.7715\n",
      "1/1 [==============================] - 6s 6s/step - loss: 16.1980\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 13.8010\n",
      "1/1 [==============================] - 8s 8s/step - loss: 14.6871\n",
      "1/1 [==============================] - 1s 882ms/step - loss: 14.0561\n",
      "1/1 [==============================] - 7s 7s/step - loss: 15.1723\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 14.6236\n",
      "1/1 [==============================] - 7s 7s/step - loss: 16.1749\n",
      "1/1 [==============================] - 1s 823ms/step - loss: 14.2632\n",
      "1/1 [==============================] - 6s 6s/step - loss: 15.5219\n",
      "1/1 [==============================] - 1s 842ms/step - loss: 13.7066\n",
      "1/1 [==============================] - 7s 7s/step - loss: 14.5747\n",
      "1/1 [==============================] - 1s 980ms/step - loss: 13.9950\n",
      "1/1 [==============================] - 6s 6s/step - loss: 15.0241\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 14.3231\n",
      "1/1 [==============================] - 6s 6s/step - loss: 15.6020\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 14.0581\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.0562\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 13.7888\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 13.7888\n",
      "[4.794584143528509, 3.7133230151222008]\n",
      "PGNNS Model Fold # 2\n",
      "1/1 [==============================] - 10s 10s/step - loss: 18.1554\n",
      "1/1 [==============================] - 5s 5s/step - loss: 48189.6562\n",
      "1/1 [==============================] - 3s 3s/step - loss: 39703.4375\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 13.3661\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.8992\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 39189.9805\n",
      "1/1 [==============================] - 3s 3s/step - loss: 32542.4746\n",
      "1/1 [==============================] - 1s 737ms/step - loss: 32907.8398\n",
      "1/1 [==============================] - 4s 4s/step - loss: 27241.8926\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 2713.7847\n",
      "1/1 [==============================] - 4s 4s/step - loss: 2256.0239\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 9311.1729\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7714.9927\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 27613.8594\n",
      "1/1 [==============================] - 3s 3s/step - loss: 22902.3750\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 16969.3086\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14081.2969\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 891.9003\n",
      "1/1 [==============================] - 4s 4s/step - loss: 757.0914\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 5936.5039\n",
      "1/1 [==============================] - 4s 4s/step - loss: 4857.9868\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 17208.6816\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14128.7695\n",
      "1/1 [==============================] - 1s 742ms/step - loss: 12489.5166\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10267.8037\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 1614.6228\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1321.0795\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 1942.8641\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1626.1888\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 9559.8223\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7932.5518\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 9633.1152\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7988.1123\n",
      "1/1 [==============================] - 1s 738ms/step - loss: 2712.1943\n",
      "1/1 [==============================] - 4s 4s/step - loss: 2268.5920\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 203.0225\n",
      "1/1 [==============================] - 4s 4s/step - loss: 169.2148\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 4459.8687\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3675.9751\n",
      "1/1 [==============================] - 1s 709ms/step - loss: 6879.8530\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5672.3032\n",
      "1/1 [==============================] - 1s 731ms/step - loss: 3502.5234\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2875.7969\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 125.3293\n",
      "1/1 [==============================] - 3s 3s/step - loss: 104.1461\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 1447.6567\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1223.6766\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 4095.0303\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3425.2683\n",
      "1/1 [==============================] - 1s 689ms/step - loss: 3340.8030\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2795.7881\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 669.1038\n",
      "1/1 [==============================] - 4s 4s/step - loss: 570.6846\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 242.2125\n",
      "1/1 [==============================] - 3s 3s/step - loss: 198.8862\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 2045.3955\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1674.8828\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 2660.9990\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2180.3643\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 1155.9733\n",
      "1/1 [==============================] - 3s 3s/step - loss: 944.9473\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 19.5778\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.4224\n",
      "1/1 [==============================] - 1s 700ms/step - loss: 725.6163\n",
      "1/1 [==============================] - 3s 3s/step - loss: 613.7201\n",
      "1/1 [==============================] - 1s 713ms/step - loss: 1668.7390\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1396.9022\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 1207.2546\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1012.5770\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 184.7879\n",
      "1/1 [==============================] - 3s 3s/step - loss: 161.2646\n",
      "1/1 [==============================] - 1s 740ms/step - loss: 164.6395\n",
      "1/1 [==============================] - 3s 3s/step - loss: 138.6368\n",
      "1/1 [==============================] - 1s 734ms/step - loss: 890.0881\n",
      "1/1 [==============================] - 4s 4s/step - loss: 735.4593\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 1011.4028\n",
      "1/1 [==============================] - 4s 4s/step - loss: 836.4691\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 367.6429\n",
      "1/1 [==============================] - 3s 3s/step - loss: 308.5913\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 14.9103\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.3896\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 373.3113\n",
      "1/1 [==============================] - 4s 4s/step - loss: 309.6974\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 693.8396\n",
      "1/1 [==============================] - 3s 3s/step - loss: 571.9347\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 431.2544\n",
      "1/1 [==============================] - 3s 3s/step - loss: 355.9533\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 48.2511\n",
      "1/1 [==============================] - 3s 3s/step - loss: 43.3534\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 110.2824\n",
      "1/1 [==============================] - 3s 3s/step - loss: 98.6197\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 390.5891\n",
      "1/1 [==============================] - 4s 4s/step - loss: 332.1234\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 370.6192\n",
      "1/1 [==============================] - 3s 3s/step - loss: 315.1266\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 103.9546\n",
      "1/1 [==============================] - 3s 3s/step - loss: 92.6965\n",
      "1/1 [==============================] - 1s 762ms/step - loss: 24.9944\n",
      "1/1 [==============================] - 4s 4s/step - loss: 25.0274\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 197.9555\n",
      "1/1 [==============================] - 4s 4s/step - loss: 165.7999\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 281.9419\n",
      "1/1 [==============================] - 3s 3s/step - loss: 234.4722\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 139.3888\n",
      "1/1 [==============================] - 3s 3s/step - loss: 117.6761\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 14.8970\n",
      "1/1 [==============================] - 4s 4s/step - loss: 16.9433\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 79.5881\n",
      "1/1 [==============================] - 4s 4s/step - loss: 72.4868\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 176.5643\n",
      "1/1 [==============================] - 3s 3s/step - loss: 153.6071\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 130.0230\n",
      "1/1 [==============================] - 3s 3s/step - loss: 114.6551\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 27.6779\n",
      "1/1 [==============================] - 3s 3s/step - loss: 28.5644\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 32.1435\n",
      "1/1 [==============================] - 3s 3s/step - loss: 30.5480\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 107.6123\n",
      "1/1 [==============================] - 4s 4s/step - loss: 91.7300\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 111.8708\n",
      "1/1 [==============================] - 3s 3s/step - loss: 95.3607\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 42.3064\n",
      "1/1 [==============================] - 3s 3s/step - loss: 38.8619\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 14.5961\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.0325\n",
      "1/1 [==============================] - 1s 718ms/step - loss: 56.4190\n",
      "1/1 [==============================] - 4s 4s/step - loss: 52.2270\n",
      "1/1 [==============================] - 1s 736ms/step - loss: 80.0591\n",
      "1/1 [==============================] - 3s 3s/step - loss: 71.8409\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 44.6856\n",
      "1/1 [==============================] - 3s 3s/step - loss: 42.2631\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 13.4235\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.8446\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 31.8618\n",
      "1/1 [==============================] - 3s 3s/step - loss: 30.5256\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 57.3101\n",
      "1/1 [==============================] - 3s 3s/step - loss: 51.2039\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 43.6976\n",
      "1/1 [==============================] - 3s 3s/step - loss: 39.9428\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 16.5838\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.0042\n",
      "1/1 [==============================] - 1s 703ms/step - loss: 18.4813\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.2427\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 37.1170\n",
      "1/1 [==============================] - 4s 4s/step - loss: 36.0652\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 35.8167\n",
      "1/1 [==============================] - 3s 3s/step - loss: 34.9480\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 18.1414\n",
      "1/1 [==============================] - 3s 3s/step - loss: 19.8624\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 14.5821\n",
      "1/1 [==============================] - 4s 4s/step - loss: 16.3091\n",
      "1/1 [==============================] - 1s 745ms/step - loss: 27.2665\n",
      "1/1 [==============================] - 4s 4s/step - loss: 26.3102\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 31.1634\n",
      "1/1 [==============================] - 3s 3s/step - loss: 29.4416\n",
      "1/1 [==============================] - 1s 721ms/step - loss: 19.9858\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.4833\n",
      "1/1 [==============================] - 1s 733ms/step - loss: 13.0838\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.2735\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 18.9756\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.5895\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 23.7915\n",
      "1/1 [==============================] - 3s 3s/step - loss: 24.7086\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 18.5377\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.1330\n",
      "1/1 [==============================] - 1s 773ms/step - loss: 13.1752\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15.2811\n",
      "1/1 [==============================] - 1s 721ms/step - loss: 16.3828\n",
      "1/1 [==============================] - 4s 4s/step - loss: 17.5435\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 20.9676\n",
      "1/1 [==============================] - 4s 4s/step - loss: 21.1329\n",
      "1/1 [==============================] - 1s 716ms/step - loss: 18.5862\n",
      "1/1 [==============================] - 3s 3s/step - loss: 19.2247\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 13.7152\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.4820\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 14.0698\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.0261\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 17.0990\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.6928\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 16.5780\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.2051\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 13.6526\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.6229\n",
      "1/1 [==============================] - 1s 696ms/step - loss: 13.5135\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.3652\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 15.8880\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.1361\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 16.1042\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.3007\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 14.0108\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.6297\n",
      "1/1 [==============================] - 1s 746ms/step - loss: 13.1998\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.0758\n",
      "1/1 [==============================] - 1s 712ms/step - loss: 14.3835\n",
      "1/1 [==============================] - 4s 4s/step - loss: 16.1682\n",
      "1/1 [==============================] - 1s 726ms/step - loss: 14.8144\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.5550\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 13.7038\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.5378\n",
      "1/1 [==============================] - 1s 748ms/step - loss: 13.1753\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 13.1753\n",
      "[4.794584143528509, 3.7133230151222008, 3.6297740411971824]\n",
      "PGNNS Model Fold # 3\n",
      "1/1 [==============================] - 8s 8s/step - loss: 17.0022\n",
      "1/1 [==============================] - 1s 1s/step - loss: 54653.9570\n",
      "1/1 [==============================] - 4s 4s/step - loss: 61739.9766\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 16.5441\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15.7840\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 43870.8086\n",
      "1/1 [==============================] - 3s 3s/step - loss: 50545.0977\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 36935.2383\n",
      "1/1 [==============================] - 3s 3s/step - loss: 42543.5547\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 3095.2222\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3653.7168\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 10404.8584\n",
      "1/1 [==============================] - 4s 4s/step - loss: 11623.7666\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 31418.5078\n",
      "1/1 [==============================] - 5s 5s/step - loss: 35411.5234\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 19843.1406\n",
      "1/1 [==============================] - 4s 4s/step - loss: 22328.1406\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 1292.6367\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1386.9509\n",
      "1/1 [==============================] - 1s 627ms/step - loss: 5975.3970\n",
      "1/1 [==============================] - 4s 4s/step - loss: 6996.4302\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 18676.0098\n",
      "1/1 [==============================] - 4s 4s/step - loss: 21626.8398\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 14187.7734\n",
      "1/1 [==============================] - 4s 4s/step - loss: 16437.0254\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 2062.1450\n",
      "1/1 [==============================] - 4s 4s/step - loss: 2452.7737\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 1905.3251\n",
      "1/1 [==============================] - 4s 4s/step - loss: 2063.8154\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 10536.0107\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11753.9814\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 11357.0703\n",
      "1/1 [==============================] - 3s 3s/step - loss: 12691.2588\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 3724.9731\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4106.4629\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 75.6447\n",
      "1/1 [==============================] - 4s 4s/step - loss: 100.3239\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 4308.4048\n",
      "1/1 [==============================] - 4s 4s/step - loss: 5043.3384\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 7519.0713\n",
      "1/1 [==============================] - 4s 4s/step - loss: 8732.2139\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 4308.9644\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5027.9312\n",
      "1/1 [==============================] - 1s 627ms/step - loss: 291.4842\n",
      "1/1 [==============================] - 4s 4s/step - loss: 360.4462\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 1267.6368\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1377.2325\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 4428.6782\n",
      "1/1 [==============================] - 4s 4s/step - loss: 4928.0913\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 4194.7041\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4664.8076\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 1200.1681\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1306.7216\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 78.1853\n",
      "1/1 [==============================] - 4s 4s/step - loss: 99.4862\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 1787.5734\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2108.4375\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 2895.2588\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3390.6748\n",
      "1/1 [==============================] - 1s 593ms/step - loss: 1592.2946\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1880.7915\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 98.7783\n",
      "1/1 [==============================] - 3s 3s/step - loss: 125.5052\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 543.1906\n",
      "1/1 [==============================] - 3s 3s/step - loss: 574.2918\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 1769.5564\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1935.6287\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 1655.1685\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1809.5126\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 480.1414\n",
      "1/1 [==============================] - 3s 3s/step - loss: 504.0652\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 39.6693\n",
      "1/1 [==============================] - 3s 3s/step - loss: 51.3770\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 694.3896\n",
      "1/1 [==============================] - 4s 4s/step - loss: 836.4952\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 1113.6243\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1325.8889\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 607.1219\n",
      "1/1 [==============================] - 3s 3s/step - loss: 731.3541\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 42.7822\n",
      "1/1 [==============================] - 4s 4s/step - loss: 54.4234\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 236.7375\n",
      "1/1 [==============================] - 3s 3s/step - loss: 240.6766\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 718.1636\n",
      "1/1 [==============================] - 3s 3s/step - loss: 768.1794\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 662.3138\n",
      "1/1 [==============================] - 4s 4s/step - loss: 705.4123\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 195.6208\n",
      "1/1 [==============================] - 5s 5s/step - loss: 194.5067\n",
      "1/1 [==============================] - 1s 818ms/step - loss: 26.7412\n",
      "1/1 [==============================] - 4s 4s/step - loss: 33.0322\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 281.0648\n",
      "1/1 [==============================] - 3s 3s/step - loss: 347.3463\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 430.4785\n",
      "1/1 [==============================] - 3s 3s/step - loss: 524.7904\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 225.2854\n",
      "1/1 [==============================] - 3s 3s/step - loss: 279.5884\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 21.7022\n",
      "1/1 [==============================] - 3s 3s/step - loss: 25.2943\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 120.5869\n",
      "1/1 [==============================] - 4s 4s/step - loss: 115.1320\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 309.0564\n",
      "1/1 [==============================] - 3s 3s/step - loss: 316.8481\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 269.4522\n",
      "1/1 [==============================] - 3s 3s/step - loss: 273.9897\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 79.8647\n",
      "1/1 [==============================] - 3s 3s/step - loss: 72.7444\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 23.0664\n",
      "1/1 [==============================] - 4s 4s/step - loss: 27.3302\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 124.5673\n",
      "1/1 [==============================] - 3s 3s/step - loss: 157.3165\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 169.6892\n",
      "1/1 [==============================] - 3s 3s/step - loss: 212.1634\n",
      "1/1 [==============================] - 1s 667ms/step - loss: 82.6392\n",
      "1/1 [==============================] - 3s 3s/step - loss: 105.1323\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 16.8364\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15.9993\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 71.5471\n",
      "1/1 [==============================] - 4s 4s/step - loss: 64.6466\n",
      "1/1 [==============================] - 1s 581ms/step - loss: 142.1978\n",
      "1/1 [==============================] - 3s 3s/step - loss: 138.1335\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 113.1428\n",
      "1/1 [==============================] - 3s 3s/step - loss: 107.4671\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 36.1821\n",
      "1/1 [==============================] - 4s 4s/step - loss: 29.6630\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 21.4335\n",
      "1/1 [==============================] - 4s 4s/step - loss: 24.7802\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 61.4971\n",
      "1/1 [==============================] - 3s 3s/step - loss: 78.6454\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 70.0244\n",
      "1/1 [==============================] - 4s 4s/step - loss: 89.4903\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 33.4117\n",
      "1/1 [==============================] - 4s 4s/step - loss: 41.8722\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 18.0803\n",
      "1/1 [==============================] - 4s 4s/step - loss: 14.8832\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 48.5419\n",
      "1/1 [==============================] - 4s 4s/step - loss: 41.2877\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 72.3867\n",
      "1/1 [==============================] - 4s 4s/step - loss: 65.0584\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 52.6290\n",
      "1/1 [==============================] - 3s 3s/step - loss: 45.1640\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 21.8453\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.9840\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 20.3088\n",
      "1/1 [==============================] - 4s 4s/step - loss: 22.5997\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 34.9384\n",
      "1/1 [==============================] - 4s 4s/step - loss: 43.6254\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 33.3992\n",
      "1/1 [==============================] - 4s 4s/step - loss: 41.3104\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 19.5596\n",
      "1/1 [==============================] - 5s 5s/step - loss: 21.0553\n",
      "1/1 [==============================] - 1s 731ms/step - loss: 20.1799\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.7376\n",
      "1/1 [==============================] - 1s 754ms/step - loss: 35.7170\n",
      "1/1 [==============================] - 4s 4s/step - loss: 28.7965\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 41.4579\n",
      "1/1 [==============================] - 4s 4s/step - loss: 34.2430\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 29.5945\n",
      "1/1 [==============================] - 4s 4s/step - loss: 23.2122\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 18.0181\n",
      "1/1 [==============================] - 4s 4s/step - loss: 14.6238\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 19.1754\n",
      "1/1 [==============================] - 4s 4s/step - loss: 20.2487\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 23.6081\n",
      "1/1 [==============================] - 4s 4s/step - loss: 27.2261\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 20.9344\n",
      "1/1 [==============================] - 4s 4s/step - loss: 23.0497\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 17.1209\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15.4245\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 21.0418\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.1825\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 27.7922\n",
      "1/1 [==============================] - 4s 4s/step - loss: 21.6888\n",
      "1/1 [==============================] - 1s 602ms/step - loss: 27.4825\n",
      "1/1 [==============================] - 4s 4s/step - loss: 21.4839\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 21.0997\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.2720\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 17.2016\n",
      "1/1 [==============================] - 5s 5s/step - loss: 14.6992\n",
      "1/1 [==============================] - 1s 729ms/step - loss: 18.2401\n",
      "1/1 [==============================] - 4s 4s/step - loss: 18.0483\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 19.1219\n",
      "1/1 [==============================] - 4s 4s/step - loss: 19.4982\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 17.6354\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.6197\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 17.5781\n",
      "1/1 [==============================] - 5s 5s/step - loss: 14.4371\n",
      "1/1 [==============================] - 1s 762ms/step - loss: 20.5797\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15.9536\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 22.8112\n",
      "1/1 [==============================] - 4s 4s/step - loss: 17.6866\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 21.2191\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.4833\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 18.2545\n",
      "1/1 [==============================] - 5s 5s/step - loss: 14.5631\n",
      "1/1 [==============================] - 1s 763ms/step - loss: 17.1524\n",
      "1/1 [==============================] - 6s 6s/step - loss: 14.9144\n",
      "1/1 [==============================] - 1s 739ms/step - loss: 17.5714\n",
      "1/1 [==============================] - 4s 4s/step - loss: 16.3090\n",
      "1/1 [==============================] - 1s 719ms/step - loss: 17.4854\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 17.4854\n",
      "[4.794584143528509, 3.7133230151222008, 3.6297740411971824, 4.1815592059886555]\n",
      "Model training and testing runtime is 49.67799336910248 minutes\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "TRAIN_SET_PERCENTAGE = 1-(1/k)\n",
    "VAL_SET_PERCENTAGE = 1/k\n",
    "PDBs.pop('',None)\n",
    "\n",
    "# PGNNS model variables\n",
    "PGNNS_train_losses = [[] for _ in range(k_fold)]\n",
    "PGNNS_val_losses = [[] for _ in range(k_fold)]\n",
    "PGNNS_rmse_train, PGNNS_rmse_test = [], []\n",
    "\n",
    "# DDS model variables\n",
    "DDS_train_losses = [[] for _ in range(k_fold)]\n",
    "DDS_val_losses = [[] for _ in range(k_fold)]\n",
    "DDS_rmse_train, DDS_rmse_test = [], []\n",
    "\n",
    "# Defining Featurizer\n",
    "featurizer = dc.feat.ConvMolFeaturizer(per_atom_fragmentation=False)\n",
    "\n",
    "# start time\n",
    "start = time.time()\n",
    "\n",
    "X, X_ids = [], []\n",
    "\n",
    "# Featurize PDB's\n",
    "for i in PDBs.keys():\n",
    "    X_ids.append(i)\n",
    "    X.append(featurizer.featurize(PDBs[i]))\n",
    "pdb_names = [i.split('-')[0] for i in X_ids] \n",
    "X = [x[0] for x in X]\n",
    "# k-fold loop\n",
    "for fold in range(k_fold):\n",
    "    # fold=0 -> 0 * (0.25 * 72) = 0\n",
    "    # fold=1 -> 1 * (0.25 * 72) = 18\n",
    "    # fold=2 -> 2 * (0.25 * 72) = 36\n",
    "    # fold=3 -> 3 * (0.25 *72) = 54\n",
    "    pdb_names_val, pdb_names_test = [], []\n",
    "    pdb_names_train, X_val_featurized, X_test_featurized, X_train_featurized  = [], [], [], []\n",
    "    \n",
    "\n",
    "     \n",
    "    TEST_SIZE = int(len(X) * VAL_SET_PERCENTAGE)\n",
    "    val_split_index_begin = int(fold * TEST_SIZE)\n",
    "#     print(f\"begin {val_split_index_begin}\")\n",
    "    val_split_index_end = int(val_split_index_begin) + int(TEST_SIZE)\n",
    "#     print(f\"end {val_split_index_end}\")\n",
    "\n",
    "    # validation\n",
    "    pdb_names_val = pdb_names[val_split_index_begin:val_split_index_end]\n",
    "\n",
    "    # Test set\n",
    "    pdb_names_test = pdb_names[val_split_index_begin:val_split_index_end]\n",
    "    \n",
    "    # Train set\n",
    "    pdb_names_train = [pdb_names[i] for i in range(len(pdb_names)) if i not in range(val_split_index_begin,val_split_index_end)]\n",
    "\n",
    "    \n",
    "    X_val_featurized = X[val_split_index_begin : val_split_index_end]\n",
    "    X_test_featurized = X[val_split_index_begin : val_split_index_end]\n",
    "    X_train_featurized = [X[i] for i in range(len(X)) if i not in range(val_split_index_begin, val_split_index_end)]\n",
    "    \n",
    "    ### Step\n",
    "    \n",
    "    x_add_train, x_add_val, x_add_test, y_train, y_val, y_test = [], [], [], [], [], []\n",
    "    # Train\n",
    "    for i in range(len(pdb_names_train)):\n",
    "        new_df = df[(df['complex-name'] == pdb_names_train[i])]\n",
    "        y_train.append(new_df['ddg'].to_numpy()[0])\n",
    "        x_add_train.append(new_df[[c for c in df.columns if ('etot' not in c) and ('delta' not in c)\n",
    "                             and ('gb-' in c or 'vdwaals' in c or 'entropy' in c)]].to_numpy()[0])\n",
    "    y_train = np.array(y_train)\n",
    "    # Val\n",
    "    for i in range(len(pdb_names_val)):\n",
    "        new_df = df[(df['complex-name'] == pdb_names_val[i])]\n",
    "        y_val.append(new_df['ddg'].to_numpy()[0])\n",
    "        x_add_val.append(new_df[[c for c in df.columns if ('etot' not in c) and ('delta' not in c)\n",
    "                             and ('gb-' in c or 'vdwaals' in c or 'entropy' in c)]].to_numpy()[0])\n",
    "    y_val = np.array(y_val)\n",
    "\n",
    "    # Test\n",
    "    for i in range(len(pdb_names_test)):\n",
    "        new_df = df[(df['complex-name'] == pdb_names_test[i])]\n",
    "        y_test.append(new_df['ddg'].to_numpy()[0])\n",
    "        x_add_test.append(new_df[[c for c in df.columns if ('etot' not in c) and ('delta' not in c)\n",
    "                             and ('gb-' in c or 'vdwaals' in c or 'entropy' in c)]].to_numpy()[0])\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    x_preprocessed_train, x_preprocessed_val, x_preprocessed_test = [], [], []\n",
    "    \n",
    "    ## Step\n",
    "    \n",
    "    # X train\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_train_featurized)\n",
    "    x_preprocessed_train = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_train.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_train.append(np.array(x_add_train))\n",
    "\n",
    "    ## X val\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_val_featurized)\n",
    "    x_preprocessed_val = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_val.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_val.append(np.array(x_add_val))\n",
    "\n",
    "\n",
    "    ## X test\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_test_featurized)\n",
    "    x_preprocessed_test = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_test.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_test.append(np.array(x_add_test))\n",
    "    \n",
    "    ### Step\n",
    "    \n",
    "    # Train\n",
    "    x_train = np.full([15, np.max([v.shape[0] for v in x_preprocessed_train]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_train if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_train):\n",
    "        if len(j.shape) > 1:\n",
    "            x_train[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_train[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_train = x_train.reshape([1] + list(x_train.shape))\n",
    "\n",
    "    # Validation\n",
    "    x_val = np.full([15, np.max([v.shape[0] for v in x_preprocessed_val]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_val if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_val):\n",
    "        if len(j.shape) > 1:\n",
    "            x_val[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_val[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_val = x_val.reshape([1] + list(x_val.shape))\n",
    "\n",
    "    # Test\n",
    "    x_test = np.full([15, np.max([v.shape[0] for v in x_preprocessed_test]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_test if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_test):\n",
    "        if len(j.shape) > 1:\n",
    "            x_test[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_test[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_test = x_test.reshape([1] + list(x_test.shape))\n",
    "    \n",
    "    # Variable initializations for models\n",
    "    \n",
    "    val_size = len(y_val)\n",
    "    train_size = len(y_train)\n",
    "    \n",
    "    # PGNNS Model\n",
    "    batch_size = len(pdb_names_train)\n",
    "    PGNNS_model = PGNNS(len(y_train))\n",
    "    PGNNS_model.compile(loss='mse', optimizer=optimizer)\n",
    "    print(f'PGNNS Model Fold # {fold}')\n",
    "    for epoch in range(max_epoch):\n",
    "        PGNNS_model.modify_graphgather(train_size)\n",
    "        PGNNS_model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "        PGNNloss = PGNNS_model.fit(x_train, y_train.reshape([1, -1]), epochs=1)\n",
    "        PGNNS_train_losses[fold].append(PGNNloss.history['loss'][0])\n",
    "        PGNNS_model.input_shapes = [i.shape for i in x_preprocessed_val]\n",
    "        PGNNS_model.modify_graphgather(val_size)\n",
    "        PGNNS_val_losses[fold].append(PGNNS_model.evaluate(x_val, y_val.reshape([1, -1])))\n",
    "        \n",
    "    PGNNS_model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "    PGNNS_model.modify_graphgather(len(y_test))\n",
    "    evalu = PGNNS_model.evaluate(x_test, y_test.reshape([1, -1]))\n",
    "    # PGNNS Testing RMSE calculation\n",
    "    PGNNS_rmse_test.append(np.sqrt(evalu))\n",
    "    print(PGNNS_rmse_test)\n",
    "    # PGNNS Training RMSE calculation\n",
    "    PGNNS_train_loss = PGNNS_train_losses[fold][-1]\n",
    "    PGNNS_rmse_train.append(math.sqrt(PGNNS_train_loss))\n",
    "    \n",
    "#     # Data Driven model\n",
    "#     DDS_model = DDS(len(y_train))\n",
    "#     DDS_model.compile(loss='mse', optimizer=optimizer)\n",
    "#     print(f'DDS Model Fold # {fold}')\n",
    "#     for epoch in range(max_epoch):\n",
    "#         DDS_model.modify_graphgather(train_size)\n",
    "#         DDS_model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "#         DDSloss = DDS_model.fit(x_train, y_train.reshape([1, -1]), epochs=1)\n",
    "#         DDS_train_losses[fold].append(DDSloss.history['loss'][0])\n",
    "#         DDS_model.input_shapes = [i.shape for i in x_preprocessed_val]\n",
    "#         DDS_model.modify_graphgather(val_size)\n",
    "#         DDS_val_losses[fold].append(DDS_model.evaluate(x_val, y_val.reshape([1, -1])))\n",
    "    \n",
    "#     DDS_model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "#     DDS_model.modify_graphgather(len(y_test))\n",
    "#     DDS_evaluate = DDS_model.evaluate(x_test, y_test.reshape([1, -1]))\n",
    "#     # DDS Testing RMSE calculation\n",
    "#     DDS_rmse_test.append(np.sqrt(DDS_evaluate))\n",
    "#     print(DDS_rmse_test)\n",
    "#     # DDS training RMSE calculation\n",
    "#     DDS_train_loss = DDS_train_losses[fold][-1]\n",
    "#     DDS_rmse_train.append(math.sqrt(DDS_train_loss))\n",
    "    \n",
    "time.sleep(1)\n",
    "# end time\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Model training and testing runtime is {(end - start)/60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21bc0c11-9e96-4449-b9e3-f749a30fd013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.664112993555332, 3.8802310951469896, 3.941799057288998, 4.038443837109572]\n"
     ]
    }
   ],
   "source": [
    " print(PGNNS_rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2438da2-f741-40be-a278-0be0b44fea42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.794584143528509, 3.7133230151222008, 3.6297740411971824, 4.1815592059886555]\n"
     ]
    }
   ],
   "source": [
    " print(PGNNS_rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12811272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.47745323],\n",
       "        [ 1.0000249 ],\n",
       "        [ 1.0000087 ],\n",
       "        [ 1.0000292 ],\n",
       "        [ 1.0001082 ],\n",
       "        [-0.9999746 ],\n",
       "        [-0.99998945],\n",
       "        [-0.9999893 ],\n",
       "        [-0.99987656],\n",
       "        [-1.0021716 ],\n",
       "        [-1.0042403 ],\n",
       "        [-0.99956393],\n",
       "        [-0.99532974],\n",
       "        [ 0.9999813 ],\n",
       "        [-1.0000001 ],\n",
       "        [-1.0072871 ],\n",
       "        [-1.0011078 ]], dtype=float32),\n",
       " array([0.00319475], dtype=float32)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chekcing the wights after training PGNNS MODEL\n",
    "PGNNS_model.layers[-1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d52642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the average RMSE on Training set\n",
    "# average_DDS_rmse_train = sum(DDS_rmse_train) / len(DDS_rmse_train)\n",
    "average_PGNNS_rmse_train = sum(PGNNS_rmse_train) / len(PGNNS_rmse_train)\n",
    "# calculating the average RMSE on Testing set\n",
    "# average_DDS_rmse_test = sum(DDS_rmse_test) / len(DDS_rmse_test)\n",
    "average_PGNNS_rmse_test = sum(PGNNS_rmse_test) / len(PGNNS_rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d44af65",
   "metadata": {},
   "source": [
    "# Model Performance Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06408c90",
   "metadata": {},
   "source": [
    "<h3>PGNNS Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc3ae960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calculating the average of k-fold losses\n",
    "average_PGNNS_train_losses = [sum(x)/len(x) for x in zip(*PGNNS_train_losses)]\n",
    "average_PGNNS_val_losses = [sum(x)/len(x) for x in zip(*PGNNS_val_losses)]\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(range(len(average_PGNNS_train_losses)), average_PGNNS_train_losses, label='train loss')\n",
    "plt.plot(range(len(average_PGNNS_val_losses)), average_PGNNS_val_losses, label='val loss')\n",
    "plt.legend(loc='upper right');\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Kcal/mol)\")\n",
    "# plt.ylim(0,100)\n",
    "plt.title(\"PGNNS Model\")\n",
    "# Time stamp with date and time\n",
    "time.strftime(\"%Y-%m-%d %H%M%S\")\n",
    "\n",
    "# save plot\n",
    "plt.savefig(\"PGNNS_loss\" + time.strftime(\"%Y-%m-%d %H%M%S\") + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed0df91",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9091230e-c768-456a-af0d-1b408f6e03f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|  PGNN No Noise 368 Datapoints  |\n",
      "+----------------+---------------+\n",
      "| PGNNS (TRAIN)  |  PGNNS (TEST) |\n",
      "+----------------+---------------+\n",
      "|      3.88      |      4.08     |\n",
      "+----------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "rmse_table = PrettyTable()\n",
    "rmse_table.title=\"PGNN No Noise 368 Datapoints\"\n",
    "rmse_table.field_names = [\"PGNNS (TRAIN)\", \"PGNNS (TEST)\"]\n",
    "rmse_table.add_row([\"{:.2f}\".format(average_PGNNS_rmse_train),\"{:.2f}\".format(average_PGNNS_rmse_test)])\n",
    "\n",
    "print(rmse_table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3ca2cdf-7ac9-4974-87a9-8657d5482158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.794584143528509, 3.7133230151222008, 3.6297740411971824, 4.1815592059886555]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PGNNS_rmse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33147a12-2ffa-4be0-bc42-a48e525ed381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance\n",
    "PGNNS_train_variance = np.std(PGNNS_rmse_train)\n",
    "PGNNS_test_variance = np.std(PGNNS_rmse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "350c285e-fd4e-4b4e-9742-1691c55b42ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4631684497773421"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PGNNS_test_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5d091c93-e06f-4269-810d-5dcf4d4acea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1374095755878466"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PGNNS_train_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3764b0-074c-4ca7-9d62-e897fd5d0299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

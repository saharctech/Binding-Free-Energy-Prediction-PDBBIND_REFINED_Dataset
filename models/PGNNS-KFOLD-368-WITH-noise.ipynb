{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2418aa36-305a-4890-8db5-efa2ddbfa398",
   "metadata": {},
   "source": [
    "<h1>test on 368 datapoints noise </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9245b7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09 21:26:37.394138: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-09 21:26:37.394169: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import rdkit\n",
    "import deepchem as dc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "import time\n",
    "from deepchem.metrics import to_one_hot\n",
    "from deepchem.feat.mol_graphs import ConvMol\n",
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "\n",
    "#K-fold\n",
    "k_fold = 4\n",
    "k = k_fold\n",
    "max_epoch = 100\n",
    "# optimizer = tf.keras.optimizers.Adagrad(0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7cb7db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021.09.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdkit.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55e66389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dc.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dcd3310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.21.4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23b2d7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5c79403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading molecular data\n",
    "df = pd.read_csv('molecule_parameters.csv')\n",
    "df.dropna(how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1de144d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.697637870606162"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DDG Standard deviation\n",
    "np.std(df.ddg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b293820-dbc0-46dc-a50f-476c71ab9a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-34.07407324'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['entropy'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82627c8e-9bf6-4b7e-b70c-d34d7521d988",
   "metadata": {},
   "source": [
    "# Adding Noise using Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06c51206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing entropy and add some noise\n",
    "df['entropy'] = df['entropy'].astype(float) + np.random.normal(np.sqrt(df['entropy'].astype(float).mean()), 1, len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "464c758b-2918-4ee7-8154-107187787a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-30.728364274673314"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['entropy'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1112109",
   "metadata": {},
   "source": [
    "# Reading PDB files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66dad05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start time\n",
    "# start = time.time()\n",
    "# # Dictionary with complex names as keys and molecule as values\n",
    "# PDBs = {}\n",
    "# from os import listdir\n",
    "# from os.path import isfile, join\n",
    "# # mypath = '../../../../../../Documents/GitHub/Binding-Free-Energy-Prediction-Host-Guest-System/pdbbind/raw-data/'\n",
    "# mypath = 'dataset234/'\n",
    "# onlyfiles = [f for f in listdir(mypath) if f not in ('.DS_Store') and f in (df['complex-name'].tolist())]\n",
    "# for f in onlyfiles:\n",
    "#     print(f)\n",
    "#     PDBs.update({f: rdkit.Chem.rdmolfiles.MolFromPDBFile(mypath + f + '/com_new.pqr')})\n",
    "\n",
    "# for key, value in dict(PDBs).items():\n",
    "#     if value is None:\n",
    "#         del PDBs[key]\n",
    "# time.sleep(1)\n",
    "# # end time\n",
    "# end = time.time()\n",
    "# # total time taken\n",
    "# print(f\"PDB file reading runtime is {(end - start)/60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "50c4732a-e78e-4dfe-9aa5-f9fe582b5bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Save PDB\n",
    "# import pickle\n",
    "# with open('PDBs-368.pkl', 'wb') as file:\n",
    "#     pickle.dump(PDBs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fedd496a-bcd2-4d0f-a36b-927c450274d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load PDB\n",
    "import pickle\n",
    "PDBs= {}\n",
    "with open('PDBs-368.pkl', 'rb') as file:\n",
    "    PDBs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c287b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly shuffling the PDBs\n",
    "import random\n",
    "l = list(PDBs.items())\n",
    "random.shuffle(l)\n",
    "PDBs = dict(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bec9a04d-7ef6-4bcb-855b-8f88003a3210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DDG distribution for dataset of ~500 datapoints\n",
    "PDB_names = list(PDBs.keys())\n",
    "df_500= pd.DataFrame()\n",
    "ddg_list= []\n",
    "for i in PDB_names:\n",
    "    ddg_list.append(float(df[df['complex-name']==i]['ddg']))\n",
    "df_500 = pd.DataFrame({'ddg': ddg_list}) \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.xlabel('ddg')\n",
    "df_500.plot.hist('ddg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4773b4b",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2808df",
   "metadata": {},
   "source": [
    "<h3>PGNNS model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b458c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "## !!!!!!!! important\n",
    "# batch_size = int(len(pdb_names_train)/4)\n",
    "# batch_size\n",
    "# batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e277cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepchem.models.layers import GraphConv, GraphPool, GraphGather\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import Dense, Input, BatchNormalization, Concatenate\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "\n",
    "class PGNNS(tf.keras.Model):\n",
    "\n",
    "  def modify_graphgather(self, batch_size):\n",
    "    self.readout.batch_size = batch_size\n",
    "    self.batch_size = batch_size\n",
    "  def __init__(self, batch_size):\n",
    "    super(PGNNS, self).__init__()\n",
    "    self.input_shapes = None\n",
    "    self.batch_size = batch_size\n",
    "    self.gc1 = GraphConv(128, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm1 = layers.BatchNormalization()\n",
    "    self.gp1 = GraphPool()\n",
    "\n",
    "    self.gc2 = GraphConv(128, activation_fn=tf.nn.tanh)\n",
    "    self.batch_norm2 = layers.BatchNormalization()\n",
    "    self.gp2 = GraphPool()\n",
    "\n",
    "    self.dense1 = layers.Dense(128, activation=tf.nn.tanh)\n",
    "    self.batch_norm3 = layers.BatchNormalization()\n",
    "    self.readout = GraphGather(batch_size=self.batch_size, activation_fn=tf.nn.tanh)\n",
    "\n",
    "    self.dense2 = layers.Dense(1)\n",
    "    self.dense3 = layers.Dense(1, \n",
    "         kernel_initializer=initializers.Constant([0.5, 1, 1, 1, 1, -1, -1, -1, -1, -1, -1, -1, -1, 1, -1, -1, -1]),\n",
    "         bias_initializer=initializers.Zeros())\n",
    "\n",
    "  def call(self, inputs):\n",
    "    inputs = inputs[0]\n",
    "    x = []\n",
    "#     input_shapes = [[4822, 75], [11, 2], [4822], [1142, 1], [1635, 2], [2042, 3],\n",
    "#                    [3, 4], [0, 5], [0, 6], [0, 7], [0, 8], [0, 9], [0, 10]]\n",
    "    for i in range(len(self.input_shapes)):\n",
    "        x.append(tf.reshape(inputs[i][inputs[i] != 1.123456], self.input_shapes[i]))\n",
    "    for i in range(1, len(self.input_shapes)):\n",
    "        x[i] = tf.cast(x[i], tf.int32)\n",
    "    x_add = tf.reshape(inputs[13][inputs[13] != 1.123456], [self.batch_size, 16])\n",
    "    gc1_output = self.gc1(x)\n",
    "    batch_norm1_output = self.batch_norm1(gc1_output)\n",
    "    gp1_output = self.gp1([batch_norm1_output] + x[1:])\n",
    "\n",
    "    gc2_output = self.gc2([gp1_output] + x[1:])\n",
    "    batch_norm2_output = self.batch_norm1(gc2_output)\n",
    "    gp2_output = self.gp2([batch_norm2_output] + x[1:])\n",
    "\n",
    "    dense1_output = self.dense1(gp2_output)\n",
    "    batch_norm3_output = self.batch_norm3(dense1_output)\n",
    "    readout_output = self.readout([batch_norm3_output] + x[1:])\n",
    "    \n",
    "    model_var = self.dense2(readout_output)\n",
    "    binding_affinity = tf.concat([model_var, x_add], axis=1)\n",
    "    return self.dense3(binding_affinity)\n",
    "# PGNNS = PGNNS(train_split_index)\n",
    "# PGNNS.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87152053-3458-44c3-90b2-77303f5e0462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df587495-c087-43fd-8488-7ce14d61b64e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PDBs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a06ba8",
   "metadata": {},
   "source": [
    "# K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bdbf0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09 21:27:50.002696: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-09 21:27:50.002733: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-09 21:27:50.002764: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (exp-1-43): /proc/driver/nvidia/version does not exist\n",
      "2022-04-09 21:27:50.003564: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PGNNS Model Fold # 0\n",
      "1/1 [==============================] - 8s 8s/step - loss: 22.6015\n",
      "1/1 [==============================] - 1s 1s/step - loss: 20597.5723\n",
      "1/1 [==============================] - 4s 4s/step - loss: 23422.2246\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 1340.2600\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1537.5386\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 4489.0659\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5036.6797\n",
      "1/1 [==============================] - 1s 709ms/step - loss: 11963.8203\n",
      "1/1 [==============================] - 4s 4s/step - loss: 13472.6309\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 9026.4307\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10158.8506\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 2582.4766\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2899.4268\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 33.7390\n",
      "1/1 [==============================] - 3s 3s/step - loss: 35.8408\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 2553.1125\n",
      "1/1 [==============================] - 4s 4s/step - loss: 2892.0984\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 5646.5664\n",
      "1/1 [==============================] - 4s 4s/step - loss: 6386.4658\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 5484.4790\n",
      "1/1 [==============================] - 4s 4s/step - loss: 6209.1797\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 2769.3782\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3124.8411\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 387.2463\n",
      "1/1 [==============================] - 3s 3s/step - loss: 433.8209\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 270.7544\n",
      "1/1 [==============================] - 4s 4s/step - loss: 308.4205\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 1878.9587\n",
      "1/1 [==============================] - 4s 4s/step - loss: 2135.0891\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 3129.7424\n",
      "1/1 [==============================] - 4s 4s/step - loss: 3554.8733\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 2733.3586\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3102.7559\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 1251.2747\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1416.7189\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 130.2636\n",
      "1/1 [==============================] - 3s 3s/step - loss: 144.7016\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 231.6272\n",
      "1/1 [==============================] - 3s 3s/step - loss: 261.6432\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 1137.6522\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1292.4414\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 1739.3828\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1975.3247\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 1425.0685\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1618.3126\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 583.4152\n",
      "1/1 [==============================] - 4s 4s/step - loss: 662.8396\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 42.3155\n",
      "1/1 [==============================] - 3s 3s/step - loss: 45.8189\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 211.2998\n",
      "1/1 [==============================] - 4s 4s/step - loss: 232.6928\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 746.0878\n",
      "1/1 [==============================] - 4s 4s/step - loss: 834.2090\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 999.0192\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1118.7964\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 718.4349\n",
      "1/1 [==============================] - 3s 3s/step - loss: 800.6639\n",
      "1/1 [==============================] - 1s 644ms/step - loss: 231.5340\n",
      "1/1 [==============================] - 4s 4s/step - loss: 252.0135\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 19.9265\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.8314\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 208.8007\n",
      "1/1 [==============================] - 3s 3s/step - loss: 242.8330\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 496.1314\n",
      "1/1 [==============================] - 3s 3s/step - loss: 575.1636\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 529.3034\n",
      "1/1 [==============================] - 3s 3s/step - loss: 613.0456\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 288.1407\n",
      "1/1 [==============================] - 3s 3s/step - loss: 334.3135\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 52.0741\n",
      "1/1 [==============================] - 4s 4s/step - loss: 59.2042\n",
      "1/1 [==============================] - 1s 616ms/step - loss: 54.8910\n",
      "1/1 [==============================] - 3s 3s/step - loss: 53.5770\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 237.4108\n",
      "1/1 [==============================] - 3s 3s/step - loss: 252.9212\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 352.8731\n",
      "1/1 [==============================] - 3s 3s/step - loss: 380.5249\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 268.8406\n",
      "1/1 [==============================] - 3s 3s/step - loss: 286.4861\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 93.7438\n",
      "1/1 [==============================] - 3s 3s/step - loss: 94.4524\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 20.0882\n",
      "1/1 [==============================] - 3s 3s/step - loss: 19.1288\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 93.7820\n",
      "1/1 [==============================] - 3s 3s/step - loss: 110.0188\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 186.7482\n",
      "1/1 [==============================] - 3s 3s/step - loss: 219.6466\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 173.2032\n",
      "1/1 [==============================] - 3s 3s/step - loss: 203.9805\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 77.4912\n",
      "1/1 [==============================] - 3s 3s/step - loss: 90.9068\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 20.0924\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.7784\n",
      "1/1 [==============================] - 1s 636ms/step - loss: 59.7115\n",
      "1/1 [==============================] - 3s 3s/step - loss: 55.8307\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 129.1510\n",
      "1/1 [==============================] - 3s 3s/step - loss: 129.3061\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 135.2774\n",
      "1/1 [==============================] - 3s 3s/step - loss: 135.1533\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 74.6838\n",
      "1/1 [==============================] - 3s 3s/step - loss: 70.3338\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 23.6357\n",
      "1/1 [==============================] - 3s 3s/step - loss: 19.2987\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 32.3777\n",
      "1/1 [==============================] - 3s 3s/step - loss: 36.4444\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 68.7823\n",
      "1/1 [==============================] - 3s 3s/step - loss: 82.2775\n",
      "1/1 [==============================] - 1s 636ms/step - loss: 73.9636\n",
      "1/1 [==============================] - 3s 3s/step - loss: 88.6362\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 42.3150\n",
      "1/1 [==============================] - 3s 3s/step - loss: 49.2388\n",
      "1/1 [==============================] - 1s 633ms/step - loss: 19.9210\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.0334\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 35.3738\n",
      "1/1 [==============================] - 3s 3s/step - loss: 29.5945\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 63.5613\n",
      "1/1 [==============================] - 3s 3s/step - loss: 57.7106\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 65.3714\n",
      "1/1 [==============================] - 3s 3s/step - loss: 59.1518\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 40.2558\n",
      "1/1 [==============================] - 3s 3s/step - loss: 33.4856\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 20.8404\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.7197\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 25.3958\n",
      "1/1 [==============================] - 3s 3s/step - loss: 26.9890\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 37.2899\n",
      "1/1 [==============================] - 3s 3s/step - loss: 43.2574\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 34.9178\n",
      "1/1 [==============================] - 3s 3s/step - loss: 40.1979\n",
      "1/1 [==============================] - 1s 633ms/step - loss: 22.9335\n",
      "1/1 [==============================] - 4s 4s/step - loss: 23.3767\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 20.9887\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.5186\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 32.7474\n",
      "1/1 [==============================] - 3s 3s/step - loss: 25.6795\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 41.6382\n",
      "1/1 [==============================] - 3s 3s/step - loss: 33.6833\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 35.9704\n",
      "1/1 [==============================] - 3s 3s/step - loss: 28.0737\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 24.1513\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.9064\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 20.0008\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.2791\n",
      "1/1 [==============================] - 1s 633ms/step - loss: 23.4733\n",
      "1/1 [==============================] - 3s 3s/step - loss: 24.2975\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 24.8408\n",
      "1/1 [==============================] - 4s 4s/step - loss: 26.4932\n",
      "1/1 [==============================] - 1s 688ms/step - loss: 21.3570\n",
      "1/1 [==============================] - 4s 4s/step - loss: 20.6658\n",
      "1/1 [==============================] - 1s 710ms/step - loss: 20.2184\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.8913\n",
      "1/1 [==============================] - 1s 607ms/step - loss: 25.2912\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.2161\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 30.5582\n",
      "1/1 [==============================] - 3s 3s/step - loss: 22.2521\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 29.1873\n",
      "1/1 [==============================] - 4s 4s/step - loss: 21.0679\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 23.4348\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.7908\n",
      "1/1 [==============================] - 1s 647ms/step - loss: 20.0050\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.8466\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 20.4169\n",
      "1/1 [==============================] - 4s 4s/step - loss: 18.5754\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 20.9314\n",
      "1/1 [==============================] - 4s 4s/step - loss: 19.7163\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 20.0262\n",
      "1/1 [==============================] - 4s 4s/step - loss: 17.3936\n",
      "1/1 [==============================] - 1s 686ms/step - loss: 20.3719\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.4302\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 23.3213\n",
      "1/1 [==============================] - 4s 4s/step - loss: 16.4058\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 25.8361\n",
      "1/1 [==============================] - 4s 4s/step - loss: 17.9621\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 24.9163\n",
      "1/1 [==============================] - 4s 4s/step - loss: 17.2612\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 21.9324\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.5404\n",
      "1/1 [==============================] - 1s 679ms/step - loss: 20.0345\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.4212\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 19.9008\n",
      "1/1 [==============================] - 4s 4s/step - loss: 16.5683\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 20.0092\n",
      "1/1 [==============================] - 4s 4s/step - loss: 16.7063\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 20.0904\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.5885\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 21.2466\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.0531\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 23.1597\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15.6709\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 24.0512\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.0624\n",
      "1/1 [==============================] - 1s 621ms/step - loss: 23.1172\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.4855\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 21.3675\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.9040\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 20.2683\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.1449\n",
      "1/1 [==============================] - 1s 651ms/step - loss: 20.0209\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.5402\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 20.0263\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 20.0263\n",
      "[4.4750758926520025]\n",
      "PGNNS Model Fold # 1\n",
      "1/1 [==============================] - 8s 8s/step - loss: 26.9179\n",
      "1/1 [==============================] - 1s 1s/step - loss: 18268.0469\n",
      "1/1 [==============================] - 4s 4s/step - loss: 22906.4316\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 25.2357\n",
      "1/1 [==============================] - 3s 3s/step - loss: 21.9586\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 15162.3125\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18956.5625\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 12422.9971\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15503.8047\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 911.7745\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1113.2468\n",
      "1/1 [==============================] - 1s 651ms/step - loss: 3950.7676\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4960.0171\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 10716.2578\n",
      "1/1 [==============================] - 3s 3s/step - loss: 13452.8701\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 6095.4512\n",
      "1/1 [==============================] - 3s 3s/step - loss: 7605.5181\n",
      "1/1 [==============================] - 1s 722ms/step - loss: 198.0331\n",
      "1/1 [==============================] - 3s 3s/step - loss: 231.1301\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 2782.4255\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3506.5859\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 6786.6279\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8515.7344\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 4252.3467\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5334.1060\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 305.4143\n",
      "1/1 [==============================] - 3s 3s/step - loss: 377.0570\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 1267.0011\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1578.1699\n",
      "1/1 [==============================] - 1s 595ms/step - loss: 4125.4614\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5170.7007\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 3335.1362\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4179.5742\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 576.3063\n",
      "1/1 [==============================] - 3s 3s/step - loss: 715.7000\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 375.0084\n",
      "1/1 [==============================] - 3s 3s/step - loss: 458.2676\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 2292.3142\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2858.9573\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 2541.0005\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3165.8254\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 815.8959\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1005.7741\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 51.7571\n",
      "1/1 [==============================] - 4s 4s/step - loss: 55.0307\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 1100.8877\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1382.3828\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 1751.9088\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2202.2620\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 882.3101\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1100.7632\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 39.7407\n",
      "1/1 [==============================] - 4s 4s/step - loss: 39.5102\n",
      "1/1 [==============================] - 1s 711ms/step - loss: 458.5737\n",
      "1/1 [==============================] - 4s 4s/step - loss: 561.8486\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 1123.1952\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1390.8210\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 815.7208\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1003.1974\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 124.0736\n",
      "1/1 [==============================] - 3s 3s/step - loss: 139.8855\n",
      "1/1 [==============================] - 1s 598ms/step - loss: 148.2798\n",
      "1/1 [==============================] - 3s 3s/step - loss: 180.3690\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 633.5687\n",
      "1/1 [==============================] - 3s 3s/step - loss: 799.3624\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 633.0446\n",
      "1/1 [==============================] - 3s 3s/step - loss: 799.5666\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 178.8471\n",
      "1/1 [==============================] - 3s 3s/step - loss: 220.9542\n",
      "1/1 [==============================] - 1s 605ms/step - loss: 47.8647\n",
      "1/1 [==============================] - 4s 4s/step - loss: 44.1588\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 357.3007\n",
      "1/1 [==============================] - 3s 3s/step - loss: 421.9292\n",
      "1/1 [==============================] - 1s 596ms/step - loss: 483.0233\n",
      "1/1 [==============================] - 3s 3s/step - loss: 577.1449\n",
      "1/1 [==============================] - 1s 603ms/step - loss: 214.9882\n",
      "1/1 [==============================] - 3s 3s/step - loss: 245.6380\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 23.7737\n",
      "1/1 [==============================] - 4s 4s/step - loss: 17.1417\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 166.4451\n",
      "1/1 [==============================] - 4s 4s/step - loss: 207.2735\n",
      "1/1 [==============================] - 1s 622ms/step - loss: 306.3081\n",
      "1/1 [==============================] - 3s 3s/step - loss: 387.5831\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 181.3744\n",
      "1/1 [==============================] - 3s 3s/step - loss: 227.2531\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 28.5845\n",
      "1/1 [==============================] - 4s 4s/step - loss: 25.3902\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 95.4976\n",
      "1/1 [==============================] - 4s 4s/step - loss: 98.1590\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 220.3783\n",
      "1/1 [==============================] - 3s 3s/step - loss: 248.2727\n",
      "1/1 [==============================] - 1s 610ms/step - loss: 170.6033\n",
      "1/1 [==============================] - 3s 3s/step - loss: 187.4533\n",
      "1/1 [==============================] - 1s 649ms/step - loss: 43.6050\n",
      "1/1 [==============================] - 3s 3s/step - loss: 36.5023\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 44.2529\n",
      "1/1 [==============================] - 4s 4s/step - loss: 47.7104\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 125.6847\n",
      "1/1 [==============================] - 3s 3s/step - loss: 155.4801\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 117.4249\n",
      "1/1 [==============================] - 3s 3s/step - loss: 144.2481\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 40.2704\n",
      "1/1 [==============================] - 3s 3s/step - loss: 41.5375\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 34.8064\n",
      "1/1 [==============================] - 4s 4s/step - loss: 26.7296\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 96.1532\n",
      "1/1 [==============================] - 4s 4s/step - loss: 97.6666\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 104.1765\n",
      "1/1 [==============================] - 3s 3s/step - loss: 106.8038\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 47.9204\n",
      "1/1 [==============================] - 3s 3s/step - loss: 40.7443\n",
      "1/1 [==============================] - 1s 611ms/step - loss: 24.9449\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.8418\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 55.6641\n",
      "1/1 [==============================] - 3s 3s/step - loss: 63.2661\n",
      "1/1 [==============================] - 1s 606ms/step - loss: 66.1751\n",
      "1/1 [==============================] - 3s 3s/step - loss: 77.8856\n",
      "1/1 [==============================] - 1s 612ms/step - loss: 36.5382\n",
      "1/1 [==============================] - 3s 3s/step - loss: 36.7866\n",
      "1/1 [==============================] - 1s 617ms/step - loss: 25.4214\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.2679\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 51.1619\n",
      "1/1 [==============================] - 3s 3s/step - loss: 43.3434\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 63.5933\n",
      "1/1 [==============================] - 3s 3s/step - loss: 57.3633\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 41.1000\n",
      "1/1 [==============================] - 3s 3s/step - loss: 32.0252\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 23.6445\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.5443\n",
      "1/1 [==============================] - 1s 666ms/step - loss: 33.0802\n",
      "1/1 [==============================] - 4s 4s/step - loss: 31.9903\n",
      "1/1 [==============================] - 1s 600ms/step - loss: 40.8170\n",
      "1/1 [==============================] - 4s 4s/step - loss: 43.1068\n",
      "1/1 [==============================] - 1s 609ms/step - loss: 30.0116\n",
      "1/1 [==============================] - 4s 4s/step - loss: 27.3280\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 23.9696\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15.2692\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 35.2671\n",
      "1/1 [==============================] - 4s 4s/step - loss: 25.4673\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 42.6343\n",
      "1/1 [==============================] - 4s 4s/step - loss: 33.4796\n",
      "1/1 [==============================] - 1s 601ms/step - loss: 33.2183\n",
      "1/1 [==============================] - 4s 4s/step - loss: 23.5424\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 23.6493\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15.1218\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 26.1999\n",
      "1/1 [==============================] - 4s 4s/step - loss: 21.5517\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 29.7428\n",
      "1/1 [==============================] - 4s 4s/step - loss: 27.0022\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 25.7437\n",
      "1/1 [==============================] - 4s 4s/step - loss: 20.4998\n",
      "1/1 [==============================] - 1s 618ms/step - loss: 23.5621\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.8806\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 29.0436\n",
      "1/1 [==============================] - 3s 3s/step - loss: 19.1074\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 32.6399\n",
      "1/1 [==============================] - 5s 5s/step - loss: 22.6788\n",
      "1/1 [==============================] - 1s 706ms/step - loss: 28.2849\n",
      "1/1 [==============================] - 5s 5s/step - loss: 18.3137\n",
      "1/1 [==============================] - 1s 608ms/step - loss: 23.5654\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.6949\n",
      "1/1 [==============================] - 1s 628ms/step - loss: 24.1532\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.6271\n",
      "1/1 [==============================] - 1s 604ms/step - loss: 25.3610\n",
      "1/1 [==============================] - 4s 4s/step - loss: 19.8084\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 23.7736\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.7356\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 23.7007\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.5358\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 26.8635\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.6389\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 28.2867\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.9040\n",
      "1/1 [==============================] - 1s 597ms/step - loss: 25.7883\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15.7035\n",
      "1/1 [==============================] - 1s 694ms/step - loss: 23.4081\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14.4330\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 23.4615\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.9455\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 23.6464\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.5613\n",
      "1/1 [==============================] - 1s 591ms/step - loss: 23.1279\n",
      "1/1 [==============================] - 5s 5s/step - loss: 14.9908\n",
      "1/1 [==============================] - 1s 713ms/step - loss: 23.7576\n",
      "1/1 [==============================] - 6s 6s/step - loss: 14.3478\n",
      "1/1 [==============================] - 1s 615ms/step - loss: 25.4643\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15.4266\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 25.7361\n",
      "1/1 [==============================] - 5s 5s/step - loss: 15.6424\n",
      "1/1 [==============================] - 1s 697ms/step - loss: 24.2133\n",
      "1/1 [==============================] - 5s 5s/step - loss: 14.5349\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 22.9960\n",
      "1/1 [==============================] - 6s 6s/step - loss: 14.2742\n",
      "1/1 [==============================] - 1s 782ms/step - loss: 22.9143\n",
      "1/1 [==============================] - 4s 4s/step - loss: 15.0234\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 22.8926\n",
      "1/1 [==============================] - 4s 4s/step - loss: 14.9994\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 22.9217\n",
      "1/1 [==============================] - 4s 4s/step - loss: 14.2419\n",
      "1/1 [==============================] - 1s 674ms/step - loss: 23.6961\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 23.6961\n",
      "[4.4750758926520025, 4.867862660711056]\n",
      "PGNNS Model Fold # 2\n",
      "1/1 [==============================] - 8s 8s/step - loss: 22.0075\n",
      "1/1 [==============================] - 1s 1s/step - loss: 45369.4023\n",
      "1/1 [==============================] - 4s 4s/step - loss: 40422.4102\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 26.3515\n",
      "1/1 [==============================] - 4s 4s/step - loss: 20.6737\n",
      "1/1 [==============================] - 1s 675ms/step - loss: 37616.4258\n",
      "1/1 [==============================] - 3s 3s/step - loss: 33130.9336\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 31492.8145\n",
      "1/1 [==============================] - 3s 3s/step - loss: 27676.5117\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 2651.1079\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2276.0508\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 8745.2959\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7911.2319\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 26058.9785\n",
      "1/1 [==============================] - 3s 3s/step - loss: 23330.7109\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 15895.4863\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14272.3926\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 796.7540\n",
      "1/1 [==============================] - 3s 3s/step - loss: 746.8305\n",
      "1/1 [==============================] - 1s 714ms/step - loss: 5781.6372\n",
      "1/1 [==============================] - 4s 4s/step - loss: 5002.9292\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 16497.4375\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14412.1484\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 11946.7871\n",
      "1/1 [==============================] - 3s 3s/step - loss: 10398.2471\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 1547.3523\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1307.3279\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 1842.0825\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1702.7961\n",
      "1/1 [==============================] - 1s 715ms/step - loss: 8980.5742\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8115.0850\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 8971.0361\n",
      "1/1 [==============================] - 3s 3s/step - loss: 8092.8433\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 2472.2278\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2258.9631\n",
      "1/1 [==============================] - 1s 707ms/step - loss: 237.7224\n",
      "1/1 [==============================] - 4s 4s/step - loss: 190.3821\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 4375.1567\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3790.8516\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 6638.0850\n",
      "1/1 [==============================] - 3s 3s/step - loss: 5764.0688\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 3351.3245\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2878.8633\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 127.4046\n",
      "1/1 [==============================] - 3s 3s/step - loss: 95.8962\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 1389.1937\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1283.7045\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 3856.6326\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3502.8989\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 3094.6113\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2815.2202\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 592.6469\n",
      "1/1 [==============================] - 3s 3s/step - loss: 555.9156\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 270.2242\n",
      "1/1 [==============================] - 3s 3s/step - loss: 220.0079\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 2012.3185\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1732.4117\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 2562.3230\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2213.2996\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 1100.4543\n",
      "1/1 [==============================] - 3s 3s/step - loss: 937.0685\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 27.0363\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.4183\n",
      "1/1 [==============================] - 1s 707ms/step - loss: 697.8654\n",
      "1/1 [==============================] - 3s 3s/step - loss: 646.7937\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 1564.7736\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1430.1165\n",
      "1/1 [==============================] - 1s 677ms/step - loss: 1105.0897\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1013.7180\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 160.9268\n",
      "1/1 [==============================] - 3s 3s/step - loss: 154.6307\n",
      "1/1 [==============================] - 1s 749ms/step - loss: 188.9985\n",
      "1/1 [==============================] - 3s 3s/step - loss: 152.5254\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 896.9134\n",
      "1/1 [==============================] - 3s 3s/step - loss: 761.1822\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 996.7526\n",
      "1/1 [==============================] - 3s 3s/step - loss: 846.9012\n",
      "1/1 [==============================] - 1s 682ms/step - loss: 366.9148\n",
      "1/1 [==============================] - 3s 3s/step - loss: 302.6236\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 22.5400\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.0423\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 346.8667\n",
      "1/1 [==============================] - 3s 3s/step - loss: 327.5161\n",
      "1/1 [==============================] - 1s 669ms/step - loss: 628.3384\n",
      "1/1 [==============================] - 3s 3s/step - loss: 584.3222\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 376.1014\n",
      "1/1 [==============================] - 3s 3s/step - loss: 353.4606\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 41.8441\n",
      "1/1 [==============================] - 3s 3s/step - loss: 40.8876\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 136.3750\n",
      "1/1 [==============================] - 3s 3s/step - loss: 108.0378\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 413.9155\n",
      "1/1 [==============================] - 3s 3s/step - loss: 343.8047\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 382.6573\n",
      "1/1 [==============================] - 3s 3s/step - loss: 316.7401\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 114.8953\n",
      "1/1 [==============================] - 3s 3s/step - loss: 89.5347\n",
      "1/1 [==============================] - 1s 766ms/step - loss: 29.8175\n",
      "1/1 [==============================] - 3s 3s/step - loss: 28.6389\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 182.0951\n",
      "1/1 [==============================] - 3s 3s/step - loss: 174.9569\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 250.7738\n",
      "1/1 [==============================] - 3s 3s/step - loss: 238.6496\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 119.0080\n",
      "1/1 [==============================] - 3s 3s/step - loss: 115.8602\n",
      "1/1 [==============================] - 1s 698ms/step - loss: 20.8668\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.3584\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 101.4907\n",
      "1/1 [==============================] - 3s 3s/step - loss: 78.6535\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 197.0053\n",
      "1/1 [==============================] - 3s 3s/step - loss: 158.7003\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 144.4058\n",
      "1/1 [==============================] - 3s 3s/step - loss: 114.6835\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 37.8817\n",
      "1/1 [==============================] - 3s 3s/step - loss: 27.8642\n",
      "1/1 [==============================] - 1s 642ms/step - loss: 35.1776\n",
      "1/1 [==============================] - 3s 3s/step - loss: 33.9102\n",
      "1/1 [==============================] - 1s 702ms/step - loss: 99.6060\n",
      "1/1 [==============================] - 3s 3s/step - loss: 96.3974\n",
      "1/1 [==============================] - 1s 676ms/step - loss: 99.8120\n",
      "1/1 [==============================] - 3s 3s/step - loss: 96.5704\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 39.2894\n",
      "1/1 [==============================] - 3s 3s/step - loss: 38.1029\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 24.9770\n",
      "1/1 [==============================] - 4s 4s/step - loss: 18.4736\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 73.0719\n",
      "1/1 [==============================] - 4s 4s/step - loss: 55.7316\n",
      "1/1 [==============================] - 1s 681ms/step - loss: 95.2623\n",
      "1/1 [==============================] - 3s 3s/step - loss: 73.7113\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 56.3381\n",
      "1/1 [==============================] - 3s 3s/step - loss: 41.9315\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 21.2301\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.2953\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 34.1207\n",
      "1/1 [==============================] - 3s 3s/step - loss: 32.8439\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 54.3487\n",
      "1/1 [==============================] - 3s 3s/step - loss: 53.1218\n",
      "1/1 [==============================] - 1s 644ms/step - loss: 41.2239\n",
      "1/1 [==============================] - 3s 3s/step - loss: 40.1232\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 21.1065\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.0856\n",
      "1/1 [==============================] - 1s 735ms/step - loss: 30.5812\n",
      "1/1 [==============================] - 4s 4s/step - loss: 21.7085\n",
      "1/1 [==============================] - 1s 704ms/step - loss: 52.0256\n",
      "1/1 [==============================] - 4s 4s/step - loss: 37.7700\n",
      "1/1 [==============================] - 1s 693ms/step - loss: 49.0590\n",
      "1/1 [==============================] - 3s 3s/step - loss: 35.4126\n",
      "1/1 [==============================] - 1s 651ms/step - loss: 28.1958\n",
      "1/1 [==============================] - 3s 3s/step - loss: 19.8592\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 20.5684\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.1678\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 29.0355\n",
      "1/1 [==============================] - 4s 4s/step - loss: 27.6292\n",
      "1/1 [==============================] - 1s 701ms/step - loss: 31.2860\n",
      "1/1 [==============================] - 3s 3s/step - loss: 30.0365\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 22.9506\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.5321\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 21.4057\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.7690\n",
      "1/1 [==============================] - 1s 655ms/step - loss: 31.2121\n",
      "1/1 [==============================] - 4s 4s/step - loss: 21.5903\n",
      "1/1 [==============================] - 1s 695ms/step - loss: 36.5696\n",
      "1/1 [==============================] - 3s 3s/step - loss: 25.3745\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 29.4087\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.2727\n",
      "1/1 [==============================] - 1s 727ms/step - loss: 21.1390\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.5842\n",
      "1/1 [==============================] - 1s 721ms/step - loss: 21.2544\n",
      "1/1 [==============================] - 4s 4s/step - loss: 18.2425\n",
      "1/1 [==============================] - 1s 738ms/step - loss: 23.8931\n",
      "1/1 [==============================] - 4s 4s/step - loss: 21.7427\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 22.0793\n",
      "1/1 [==============================] - 3s 3s/step - loss: 19.4324\n",
      "1/1 [==============================] - 1s 724ms/step - loss: 20.1634\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.7001\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 23.5945\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.5219\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 28.0513\n",
      "1/1 [==============================] - 3s 3s/step - loss: 19.2046\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 26.9441\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.4440\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 22.2570\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.7899\n",
      "1/1 [==============================] - 1s 705ms/step - loss: 20.0503\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.6830\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 20.7183\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.5073\n",
      "1/1 [==============================] - 1s 683ms/step - loss: 20.7273\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.5198\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 19.9780\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.7583\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 21.1928\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.2886\n",
      "1/1 [==============================] - 1s 673ms/step - loss: 23.8071\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.4426\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 24.3393\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.7259\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 22.2631\n",
      "1/1 [==============================] - 3s 3s/step - loss: 15.6309\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 20.2731\n",
      "1/1 [==============================] - 1s 685ms/step - loss: 20.2731\n",
      "[4.4750758926520025, 4.867862660711056, 4.502565288504553]\n",
      "PGNNS Model Fold # 3\n",
      "1/1 [==============================] - 7s 7s/step - loss: 24.0237\n",
      "1/1 [==============================] - 1s 1s/step - loss: 68401.3125\n",
      "1/1 [==============================] - 3s 3s/step - loss: 56501.3320\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 21.8336\n",
      "1/1 [==============================] - 3s 3s/step - loss: 21.2635\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 56223.4570\n",
      "1/1 [==============================] - 3s 3s/step - loss: 46160.8633\n",
      "1/1 [==============================] - 1s 624ms/step - loss: 47210.0234\n",
      "1/1 [==============================] - 3s 3s/step - loss: 38720.4844\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 4015.7874\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3249.5867\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 13030.1143\n",
      "1/1 [==============================] - 4s 4s/step - loss: 10816.5566\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 39214.4766\n",
      "1/1 [==============================] - 4s 4s/step - loss: 32405.3145\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 24341.7910\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20123.2188\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 1373.6700\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1155.1830\n",
      "1/1 [==============================] - 1s 620ms/step - loss: 8111.0264\n",
      "1/1 [==============================] - 3s 3s/step - loss: 6651.2905\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 24197.8496\n",
      "1/1 [==============================] - 3s 3s/step - loss: 19874.5527\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 17957.9863\n",
      "1/1 [==============================] - 3s 3s/step - loss: 14759.1934\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 2504.3997\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2056.3887\n",
      "1/1 [==============================] - 1s 671ms/step - loss: 2513.7109\n",
      "1/1 [==============================] - 3s 3s/step - loss: 2075.2898\n",
      "1/1 [==============================] - 1s 658ms/step - loss: 13274.3193\n",
      "1/1 [==============================] - 4s 4s/step - loss: 10945.9199\n",
      "1/1 [==============================] - 1s 664ms/step - loss: 13881.9160\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11455.2266\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 4241.4663\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3511.0708\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 178.8977\n",
      "1/1 [==============================] - 3s 3s/step - loss: 147.6335\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 5909.5244\n",
      "1/1 [==============================] - 4s 4s/step - loss: 4839.9609\n",
      "1/1 [==============================] - 1s 687ms/step - loss: 9779.4307\n",
      "1/1 [==============================] - 4s 4s/step - loss: 7985.9111\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 5388.2192\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4383.3833\n",
      "1/1 [==============================] - 1s 629ms/step - loss: 318.2570\n",
      "1/1 [==============================] - 3s 3s/step - loss: 253.6383\n",
      "1/1 [==============================] - 1s 614ms/step - loss: 1690.1050\n",
      "1/1 [==============================] - 4s 4s/step - loss: 1421.3102\n",
      "1/1 [==============================] - 1s 747ms/step - loss: 5546.7080\n",
      "1/1 [==============================] - 4s 4s/step - loss: 4618.8750\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 4999.8916\n",
      "1/1 [==============================] - 3s 3s/step - loss: 4155.5322\n",
      "1/1 [==============================] - 1s 632ms/step - loss: 1260.3690\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1059.2344\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 177.4173\n",
      "1/1 [==============================] - 3s 3s/step - loss: 143.7281\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 2532.6990\n",
      "1/1 [==============================] - 4s 4s/step - loss: 2064.2109\n",
      "1/1 [==============================] - 1s 699ms/step - loss: 3796.6169\n",
      "1/1 [==============================] - 3s 3s/step - loss: 3097.7534\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 1970.5947\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1602.6578\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 99.9490\n",
      "1/1 [==============================] - 3s 3s/step - loss: 80.7629\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 727.4056\n",
      "1/1 [==============================] - 3s 3s/step - loss: 618.1075\n",
      "1/1 [==============================] - 1s 657ms/step - loss: 2186.4856\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1832.0536\n",
      "1/1 [==============================] - 1s 623ms/step - loss: 1902.1328\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1597.4905\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 456.9309\n",
      "1/1 [==============================] - 3s 3s/step - loss: 393.1887\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 98.9785\n",
      "1/1 [==============================] - 3s 3s/step - loss: 78.4248\n",
      "1/1 [==============================] - 1s 656ms/step - loss: 1043.1349\n",
      "1/1 [==============================] - 4s 4s/step - loss: 837.8888\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 1507.4426\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1213.1727\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 767.0699\n",
      "1/1 [==============================] - 3s 3s/step - loss: 611.3962\n",
      "1/1 [==============================] - 1s 663ms/step - loss: 45.7382\n",
      "1/1 [==============================] - 3s 3s/step - loss: 36.3003\n",
      "1/1 [==============================] - 1s 726ms/step - loss: 307.1941\n",
      "1/1 [==============================] - 4s 4s/step - loss: 270.0086\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 858.6608\n",
      "1/1 [==============================] - 3s 3s/step - loss: 734.9071\n",
      "1/1 [==============================] - 1s 665ms/step - loss: 719.3268\n",
      "1/1 [==============================] - 3s 3s/step - loss: 618.2979\n",
      "1/1 [==============================] - 1s 653ms/step - loss: 162.9680\n",
      "1/1 [==============================] - 3s 3s/step - loss: 147.5501\n",
      "1/1 [==============================] - 1s 717ms/step - loss: 64.5984\n",
      "1/1 [==============================] - 3s 3s/step - loss: 49.9197\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 451.7086\n",
      "1/1 [==============================] - 3s 3s/step - loss: 355.5754\n",
      "1/1 [==============================] - 1s 672ms/step - loss: 608.4506\n",
      "1/1 [==============================] - 3s 3s/step - loss: 480.9407\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 295.7742\n",
      "1/1 [==============================] - 3s 3s/step - loss: 230.2669\n",
      "1/1 [==============================] - 1s 662ms/step - loss: 25.0606\n",
      "1/1 [==============================] - 4s 4s/step - loss: 20.9379\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 144.8137\n",
      "1/1 [==============================] - 4s 4s/step - loss: 132.5361\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 347.3185\n",
      "1/1 [==============================] - 3s 3s/step - loss: 305.9755\n",
      "1/1 [==============================] - 1s 650ms/step - loss: 268.4441\n",
      "1/1 [==============================] - 3s 3s/step - loss: 238.7167\n",
      "1/1 [==============================] - 1s 660ms/step - loss: 57.4467\n",
      "1/1 [==============================] - 4s 4s/step - loss: 55.6628\n",
      "1/1 [==============================] - 1s 639ms/step - loss: 49.3987\n",
      "1/1 [==============================] - 4s 4s/step - loss: 38.3441\n",
      "1/1 [==============================] - 1s 720ms/step - loss: 210.1768\n",
      "1/1 [==============================] - 3s 3s/step - loss: 163.2177\n",
      "1/1 [==============================] - 1s 690ms/step - loss: 249.7853\n",
      "1/1 [==============================] - 3s 3s/step - loss: 194.7124\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 112.2642\n",
      "1/1 [==============================] - 4s 4s/step - loss: 86.4068\n",
      "1/1 [==============================] - 1s 630ms/step - loss: 18.8279\n",
      "1/1 [==============================] - 4s 4s/step - loss: 17.6386\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 79.0457\n",
      "1/1 [==============================] - 4s 4s/step - loss: 74.4299\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 147.9712\n",
      "1/1 [==============================] - 3s 3s/step - loss: 134.1935\n",
      "1/1 [==============================] - 1s 668ms/step - loss: 101.3477\n",
      "1/1 [==============================] - 4s 4s/step - loss: 93.8208\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 25.0940\n",
      "1/1 [==============================] - 4s 4s/step - loss: 25.3939\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 40.7737\n",
      "1/1 [==============================] - 4s 4s/step - loss: 32.0767\n",
      "1/1 [==============================] - 1s 735ms/step - loss: 105.5991\n",
      "1/1 [==============================] - 3s 3s/step - loss: 81.9225\n",
      "1/1 [==============================] - 1s 691ms/step - loss: 106.1394\n",
      "1/1 [==============================] - 3s 3s/step - loss: 82.5147\n",
      "1/1 [==============================] - 1s 641ms/step - loss: 45.5568\n",
      "1/1 [==============================] - 4s 4s/step - loss: 36.0636\n",
      "1/1 [==============================] - 1s 627ms/step - loss: 18.3323\n",
      "1/1 [==============================] - 4s 4s/step - loss: 18.3130\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 48.5090\n",
      "1/1 [==============================] - 3s 3s/step - loss: 46.5727\n",
      "1/1 [==============================] - 1s 654ms/step - loss: 67.8420\n",
      "1/1 [==============================] - 3s 3s/step - loss: 63.5541\n",
      "1/1 [==============================] - 1s 638ms/step - loss: 42.1232\n",
      "1/1 [==============================] - 4s 4s/step - loss: 40.7271\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 17.9647\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.6807\n",
      "1/1 [==============================] - 1s 646ms/step - loss: 33.5970\n",
      "1/1 [==============================] - 3s 3s/step - loss: 27.3620\n",
      "1/1 [==============================] - 1s 661ms/step - loss: 57.6054\n",
      "1/1 [==============================] - 3s 3s/step - loss: 45.4368\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 49.3814\n",
      "1/1 [==============================] - 4s 4s/step - loss: 39.1206\n",
      "1/1 [==============================] - 1s 723ms/step - loss: 24.1745\n",
      "1/1 [==============================] - 4s 4s/step - loss: 20.5158\n",
      "1/1 [==============================] - 1s 634ms/step - loss: 19.0947\n",
      "1/1 [==============================] - 4s 4s/step - loss: 19.0876\n",
      "1/1 [==============================] - 1s 709ms/step - loss: 32.2096\n",
      "1/1 [==============================] - 3s 3s/step - loss: 31.8566\n",
      "1/1 [==============================] - 1s 636ms/step - loss: 34.6443\n",
      "1/1 [==============================] - 3s 3s/step - loss: 34.1248\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 22.4464\n",
      "1/1 [==============================] - 3s 3s/step - loss: 22.6337\n",
      "1/1 [==============================] - 1s 670ms/step - loss: 18.1646\n",
      "1/1 [==============================] - 4s 4s/step - loss: 16.7161\n",
      "1/1 [==============================] - 1s 635ms/step - loss: 28.8466\n",
      "1/1 [==============================] - 3s 3s/step - loss: 23.3997\n",
      "1/1 [==============================] - 1s 644ms/step - loss: 35.9879\n",
      "1/1 [==============================] - 3s 3s/step - loss: 28.4651\n",
      "1/1 [==============================] - 1s 626ms/step - loss: 28.5205\n",
      "1/1 [==============================] - 3s 3s/step - loss: 23.0497\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 18.6809\n",
      "1/1 [==============================] - 3s 3s/step - loss: 16.7555\n",
      "1/1 [==============================] - 1s 613ms/step - loss: 19.0134\n",
      "1/1 [==============================] - 4s 4s/step - loss: 18.9252\n",
      "1/1 [==============================] - 1s 648ms/step - loss: 23.5140\n",
      "1/1 [==============================] - 3s 3s/step - loss: 23.6717\n",
      "1/1 [==============================] - 1s 684ms/step - loss: 22.0077\n",
      "1/1 [==============================] - 3s 3s/step - loss: 22.1541\n",
      "1/1 [==============================] - 1s 678ms/step - loss: 17.7812\n",
      "1/1 [==============================] - 4s 4s/step - loss: 17.3058\n",
      "1/1 [==============================] - 1s 768ms/step - loss: 19.3806\n",
      "1/1 [==============================] - 4s 4s/step - loss: 16.9348\n",
      "1/1 [==============================] - 1s 692ms/step - loss: 24.7997\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.2261\n",
      "1/1 [==============================] - 1s 637ms/step - loss: 25.5547\n",
      "1/1 [==============================] - 3s 3s/step - loss: 20.6845\n",
      "1/1 [==============================] - 1s 643ms/step - loss: 20.8396\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.6526\n",
      "1/1 [==============================] - 1s 680ms/step - loss: 17.5132\n",
      "1/1 [==============================] - 4s 4s/step - loss: 16.2654\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 18.3182\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.0894\n",
      "1/1 [==============================] - 1s 645ms/step - loss: 19.2431\n",
      "1/1 [==============================] - 3s 3s/step - loss: 19.2169\n",
      "1/1 [==============================] - 1s 651ms/step - loss: 17.9776\n",
      "1/1 [==============================] - 3s 3s/step - loss: 17.6531\n",
      "1/1 [==============================] - 1s 631ms/step - loss: 17.4594\n",
      "1/1 [==============================] - 4s 4s/step - loss: 16.1399\n",
      "1/1 [==============================] - 1s 652ms/step - loss: 19.6285\n",
      "1/1 [==============================] - 5s 5s/step - loss: 16.8773\n",
      "1/1 [==============================] - 1s 625ms/step - loss: 21.6153\n",
      "1/1 [==============================] - 3s 3s/step - loss: 18.0077\n",
      "1/1 [==============================] - 1s 619ms/step - loss: 20.5412\n",
      "1/1 [==============================] - 1s 640ms/step - loss: 20.5412\n",
      "[4.4750758926520025, 4.867862660711056, 4.502565288504553, 4.532238030414009]\n",
      "Model training and testing runtime is 46.34976100126902 minutes\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "TRAIN_SET_PERCENTAGE = 1-(1/k)\n",
    "VAL_SET_PERCENTAGE = 1/k\n",
    "PDBs.pop('',None)\n",
    "\n",
    "# PGNNS model variables\n",
    "PGNNS_train_losses = [[] for _ in range(k_fold)]\n",
    "PGNNS_val_losses = [[] for _ in range(k_fold)]\n",
    "PGNNS_rmse_train, PGNNS_rmse_test = [], []\n",
    "\n",
    "# DDS model variables\n",
    "DDS_train_losses = [[] for _ in range(k_fold)]\n",
    "DDS_val_losses = [[] for _ in range(k_fold)]\n",
    "DDS_rmse_train, DDS_rmse_test = [], []\n",
    "\n",
    "# Defining Featurizer\n",
    "featurizer = dc.feat.ConvMolFeaturizer(per_atom_fragmentation=False)\n",
    "\n",
    "# start time\n",
    "start = time.time()\n",
    "\n",
    "X, X_ids = [], []\n",
    "\n",
    "# Featurize PDB's\n",
    "for i in PDBs.keys():\n",
    "    X_ids.append(i)\n",
    "    X.append(featurizer.featurize(PDBs[i]))\n",
    "pdb_names = [i.split('-')[0] for i in X_ids] \n",
    "X = [x[0] for x in X]\n",
    "# k-fold loop\n",
    "for fold in range(k_fold):\n",
    "    # fold=0 -> 0 * (0.25 * 72) = 0\n",
    "    # fold=1 -> 1 * (0.25 * 72) = 18\n",
    "    # fold=2 -> 2 * (0.25 * 72) = 36\n",
    "    # fold=3 -> 3 * (0.25 *72) = 54\n",
    "    pdb_names_val, pdb_names_test = [], []\n",
    "    pdb_names_train, X_val_featurized, X_test_featurized, X_train_featurized  = [], [], [], []\n",
    "    \n",
    "\n",
    "     \n",
    "    TEST_SIZE = int(len(X) * VAL_SET_PERCENTAGE)\n",
    "    val_split_index_begin = int(fold * TEST_SIZE)\n",
    "#     print(f\"begin {val_split_index_begin}\")\n",
    "    val_split_index_end = int(val_split_index_begin) + int(TEST_SIZE)\n",
    "#     print(f\"end {val_split_index_end}\")\n",
    "\n",
    "    # validation\n",
    "    pdb_names_val = pdb_names[val_split_index_begin:val_split_index_end]\n",
    "\n",
    "    # Test set\n",
    "    pdb_names_test = pdb_names[val_split_index_begin:val_split_index_end]\n",
    "    \n",
    "    # Train set\n",
    "    pdb_names_train = [pdb_names[i] for i in range(len(pdb_names)) if i not in range(val_split_index_begin,val_split_index_end)]\n",
    "\n",
    "    \n",
    "    X_val_featurized = X[val_split_index_begin : val_split_index_end]\n",
    "    X_test_featurized = X[val_split_index_begin : val_split_index_end]\n",
    "    X_train_featurized = [X[i] for i in range(len(X)) if i not in range(val_split_index_begin, val_split_index_end)]\n",
    "    \n",
    "    ### Step\n",
    "    \n",
    "    x_add_train, x_add_val, x_add_test, y_train, y_val, y_test = [], [], [], [], [], []\n",
    "    # Train\n",
    "    for i in range(len(pdb_names_train)):\n",
    "        new_df = df[(df['complex-name'] == pdb_names_train[i])]\n",
    "        y_train.append(new_df['ddg'].to_numpy()[0])\n",
    "        x_add_train.append(new_df[[c for c in df.columns if ('etot' not in c) and ('delta' not in c)\n",
    "                             and ('gb-' in c or 'vdwaals' in c or 'entropy' in c)]].to_numpy()[0])\n",
    "    y_train = np.array(y_train)\n",
    "    # Val\n",
    "    for i in range(len(pdb_names_val)):\n",
    "        new_df = df[(df['complex-name'] == pdb_names_val[i])]\n",
    "        y_val.append(new_df['ddg'].to_numpy()[0])\n",
    "        x_add_val.append(new_df[[c for c in df.columns if ('etot' not in c) and ('delta' not in c)\n",
    "                             and ('gb-' in c or 'vdwaals' in c or 'entropy' in c)]].to_numpy()[0])\n",
    "    y_val = np.array(y_val)\n",
    "\n",
    "    # Test\n",
    "    for i in range(len(pdb_names_test)):\n",
    "        new_df = df[(df['complex-name'] == pdb_names_test[i])]\n",
    "        y_test.append(new_df['ddg'].to_numpy()[0])\n",
    "        x_add_test.append(new_df[[c for c in df.columns if ('etot' not in c) and ('delta' not in c)\n",
    "                             and ('gb-' in c or 'vdwaals' in c or 'entropy' in c)]].to_numpy()[0])\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    x_preprocessed_train, x_preprocessed_val, x_preprocessed_test = [], [], []\n",
    "    \n",
    "    ## Step\n",
    "    \n",
    "    # X train\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_train_featurized)\n",
    "    x_preprocessed_train = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_train.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_train.append(np.array(x_add_train))\n",
    "\n",
    "    ## X val\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_val_featurized)\n",
    "    x_preprocessed_val = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_val.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_val.append(np.array(x_add_val))\n",
    "\n",
    "\n",
    "    ## X test\n",
    "    multiConvMol = ConvMol.agglomerate_mols(X_test_featurized)\n",
    "    x_preprocessed_test = [multiConvMol.get_atom_features(), multiConvMol.deg_slice, np.array(multiConvMol.membership)]\n",
    "    for i in range(1, len(multiConvMol.get_deg_adjacency_lists())):\n",
    "        x_preprocessed_test.append(multiConvMol.get_deg_adjacency_lists()[i])\n",
    "    x_preprocessed_test.append(np.array(x_add_test))\n",
    "    \n",
    "    ### Step\n",
    "    \n",
    "    # Train\n",
    "    x_train = np.full([15, np.max([v.shape[0] for v in x_preprocessed_train]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_train if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_train):\n",
    "        if len(j.shape) > 1:\n",
    "            x_train[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_train[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_train = x_train.reshape([1] + list(x_train.shape))\n",
    "\n",
    "    # Validation\n",
    "    x_val = np.full([15, np.max([v.shape[0] for v in x_preprocessed_val]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_val if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_val):\n",
    "        if len(j.shape) > 1:\n",
    "            x_val[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_val[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_val = x_val.reshape([1] + list(x_val.shape))\n",
    "\n",
    "    # Test\n",
    "    x_test = np.full([15, np.max([v.shape[0] for v in x_preprocessed_test]),\n",
    "                      np.max([v.shape[1] for v in x_preprocessed_test if len(v.shape) > 1])], 1.123456)\n",
    "    for i,j in enumerate(x_preprocessed_test):\n",
    "        if len(j.shape) > 1:\n",
    "            x_test[i][:j.shape[0],:j.shape[1]] = np.array(j)\n",
    "        else:\n",
    "            x_test[i][:len(j), :1] = np.array(j).reshape(j.shape[0], 1)\n",
    "    x_test = x_test.reshape([1] + list(x_test.shape))\n",
    "    \n",
    "    # Variable initializations for models\n",
    "    \n",
    "    val_size = len(y_val)\n",
    "    train_size = len(y_train)\n",
    "    \n",
    "    # PGNNS Model\n",
    "    batch_size = len(pdb_names_train)\n",
    "    PGNNS_model = PGNNS(len(y_train))\n",
    "    PGNNS_model.compile(loss='mse', optimizer=optimizer)\n",
    "    print(f'PGNNS Model Fold # {fold}')\n",
    "    for epoch in range(max_epoch):\n",
    "        PGNNS_model.modify_graphgather(train_size)\n",
    "        PGNNS_model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "        PGNNloss = PGNNS_model.fit(x_train, y_train.reshape([1, -1]), epochs=1)\n",
    "        PGNNS_train_losses[fold].append(PGNNloss.history['loss'][0])\n",
    "        PGNNS_model.input_shapes = [i.shape for i in x_preprocessed_val]\n",
    "        PGNNS_model.modify_graphgather(val_size)\n",
    "        PGNNS_val_losses[fold].append(PGNNS_model.evaluate(x_val, y_val.reshape([1, -1])))\n",
    "        \n",
    "    PGNNS_model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "    PGNNS_model.modify_graphgather(len(y_test))\n",
    "    evalu = PGNNS_model.evaluate(x_test, y_test.reshape([1, -1]))\n",
    "    # PGNNS Testing RMSE calculation\n",
    "    PGNNS_rmse_test.append(np.sqrt(evalu))\n",
    "    print(PGNNS_rmse_test)\n",
    "    # PGNNS Training RMSE calculation\n",
    "    PGNNS_train_loss = PGNNS_train_losses[fold][-1]\n",
    "    PGNNS_rmse_train.append(math.sqrt(PGNNS_train_loss))\n",
    "    \n",
    "#     # Data Driven model\n",
    "#     DDS_model = DDS(len(y_train))\n",
    "#     DDS_model.compile(loss='mse', optimizer=optimizer)\n",
    "#     print(f'DDS Model Fold # {fold}')\n",
    "#     for epoch in range(max_epoch):\n",
    "#         DDS_model.modify_graphgather(train_size)\n",
    "#         DDS_model.input_shapes = [i.shape for i in x_preprocessed_train]\n",
    "#         DDSloss = DDS_model.fit(x_train, y_train.reshape([1, -1]), epochs=1)\n",
    "#         DDS_train_losses[fold].append(DDSloss.history['loss'][0])\n",
    "#         DDS_model.input_shapes = [i.shape for i in x_preprocessed_val]\n",
    "#         DDS_model.modify_graphgather(val_size)\n",
    "#         DDS_val_losses[fold].append(DDS_model.evaluate(x_val, y_val.reshape([1, -1])))\n",
    "    \n",
    "#     DDS_model.input_shapes = [i.shape for i in x_preprocessed_test]\n",
    "#     DDS_model.modify_graphgather(len(y_test))\n",
    "#     DDS_evaluate = DDS_model.evaluate(x_test, y_test.reshape([1, -1]))\n",
    "#     # DDS Testing RMSE calculation\n",
    "#     DDS_rmse_test.append(np.sqrt(DDS_evaluate))\n",
    "#     print(DDS_rmse_test)\n",
    "#     # DDS training RMSE calculation\n",
    "#     DDS_train_loss = DDS_train_losses[fold][-1]\n",
    "#     DDS_rmse_train.append(math.sqrt(DDS_train_loss))\n",
    "    \n",
    "time.sleep(1)\n",
    "# end time\n",
    "end = time.time()\n",
    "# total time taken\n",
    "print(f\"Model training and testing runtime is {(end - start)/60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2fa7465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "368"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(PDBs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be0c6297-b6da-46fa-9f61-1ab5d812b97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.942107396289065, 3.7738484224042708, 3.9535928683032524, 4.243542196722711]\n"
     ]
    }
   ],
   "source": [
    "print(PGNNS_rmse_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33116246-4ae8-4a7c-aeb3-11acd8bbcef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.4750758926520025, 4.867862660711056, 4.502565288504553, 4.532238030414009]\n"
     ]
    }
   ],
   "source": [
    "print(PGNNS_rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12811272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.45457432],\n",
       "        [ 1.0000126 ],\n",
       "        [ 1.000002  ],\n",
       "        [ 1.0000442 ],\n",
       "        [ 1.0005797 ],\n",
       "        [-0.99998665],\n",
       "        [-0.9999865 ],\n",
       "        [-0.9999812 ],\n",
       "        [-0.99937934],\n",
       "        [-1.0035686 ],\n",
       "        [-1.0066755 ],\n",
       "        [-1.0031843 ],\n",
       "        [-0.99358433],\n",
       "        [ 0.9999912 ],\n",
       "        [-0.9999488 ],\n",
       "        [-1.0102943 ],\n",
       "        [-0.99892503]], dtype=float32),\n",
       " array([0.00406112], dtype=float32)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chekcing the wights after training PGNNS MODEL\n",
    "PGNNS_model.layers[-1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d52642a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the average RMSE on Training set\n",
    "# average_DDS_rmse_train = sum(DDS_rmse_train) / len(DDS_rmse_train)\n",
    "average_PGNNS_rmse_train = sum(PGNNS_rmse_train) / len(PGNNS_rmse_train)\n",
    "# calculating the average RMSE on Testing set\n",
    "# average_DDS_rmse_test = sum(DDS_rmse_test) / len(DDS_rmse_test)\n",
    "average_PGNNS_rmse_test = sum(PGNNS_rmse_test) / len(PGNNS_rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d44af65",
   "metadata": {},
   "source": [
    "# Model Performance Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06408c90",
   "metadata": {},
   "source": [
    "<h3>PGNNS Model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc3ae960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Calculating the average of k-fold losses\n",
    "average_PGNNS_train_losses = [sum(x)/len(x) for x in zip(*PGNNS_train_losses)]\n",
    "average_PGNNS_val_losses = [sum(x)/len(x) for x in zip(*PGNNS_val_losses)]\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(range(len(average_PGNNS_train_losses)), average_PGNNS_train_losses, label='train loss')\n",
    "plt.plot(range(len(average_PGNNS_val_losses)), average_PGNNS_val_losses, label='val loss')\n",
    "plt.legend(loc='upper right');\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (Kcal/mol)\")\n",
    "# plt.ylim(0,100)\n",
    "plt.title(\"PGNNS Model\")\n",
    "# Time stamp with date and time\n",
    "time.strftime(\"%Y-%m-%d %H%M%S\")\n",
    "\n",
    "# save plot\n",
    "plt.savefig(\"PGNNS_loss\" + time.strftime(\"%Y-%m-%d %H%M%S\") + \".png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed0df91",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9289cd1e-ad10-4f7f-907c-d6c603966e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|      Models Comparison       |\n",
      "+---------------+--------------+\n",
      "| PGNNS (TRAIN) | PGNNS (TEST) |\n",
      "+---------------+--------------+\n",
      "|      3.98     |     4.59     |\n",
      "+---------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "rmse_table = PrettyTable()\n",
    "rmse_table.title=\"Models Comparison\"\n",
    "rmse_table.field_names = [\"PGNNS (TRAIN)\", \"PGNNS (TEST)\"]\n",
    "rmse_table.add_row([\"{:.2f}\".format(average_PGNNS_rmse_train),\"{:.2f}\".format(average_PGNNS_rmse_test)])\n",
    "\n",
    "print(rmse_table) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d479df20-97a6-431d-a3d9-0d7b1d55bf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance\n",
    "PGNNS_train_variance = np.std(PGNNS_rmse_train)\n",
    "PGNNS_test_variance = np.std(PGNNS_rmse_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03e005e-5dfe-4ba5-bf88-61f7d6c29054",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d8e6a49-ac9f-409a-8868-323db35244b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1591522769738877"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PGNNS_test_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2b27213d-fae5-422d-a861-517de9b06759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1688743722765078"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PGNNS_train_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d172386b-4889-41a8-a227-9afcf1b06cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
